#+TITLE: A Markovian model for spatio-temporal population dynamics in neocortex
#+AUTHOR:  Collab.: S. Chemla^1 & F. Chavane^1 (/in vivo/ VSD imaging)
#+DATE:  \textsc{Y. Zerlaut}^2 & \textsc{A. Destexhe}^2 
#+INCLUDE: jphysiol_template.org

* Key points summary :noexport:
\bfseries

- We investigate whether the markovian formalism proposed in
  [[citetext:ElBoustani2009]] allows to describe the population dynamics
  of a network of excitatory and inhibitory neurons with different
  electrophysiological properties.

- Comparison with numerical simulations.

- Investigating the integrative properties of the mean field model.

- Implementation in a ring geometry to describe the spatial
  integration across the neocortical sheet.

- Comparison with optical imaging of spatio-temporal dynamics in the
  primary visual cortex of awake behaving monkey (Chemla & Chavane,
  unpublished results).

\normalfont

* Abstract
\bfseries

While voltage sensitive dye imaging (VSDi) has been shown to be a
decisive tool in the exploration of how neural population dynamics
shape cortical function, to our knowledge, no theoretical model offers
a detailed account of the link between neural dynamics and the source
signal at the large spatial scale imaged by optical imaging (\(\sim\)
100mm^2).

In this communication, we take advantage of the extensive theoretical
work performed at the mesoscopic scale (\(\sim\) 10000 neurons,
0.25mm^2) to analytically describe population dynamics in terms of few
variables (the so-called /mean-field/ approach to network dynamics) to
build a large scale model of population dynamics but still with a
correlate in terms of single-cell dynamics (in particular membrane
potential dynamics) so that the model can directly generate
predictions for the signal imaged by the VSDi technique.

The first part establishes the validity and weaknesses of the
mesoscopic description of network dynamics used to model the activity
of a single cortical column. By comparing its prediction with
numerical simulations of artificial neural networks, we investigate
whether the markovian formalism proposed in [[citetext:ElBoustani2009]]
allows to describe the dynamics of a network of excitatory and
inhibitory neurons with different electrophysiological properties. In
particular, we investigate whether this formalism generalizes to the
description of network dynamics in the presence of time-dependent
inputs. 

We next analyze the integrative properties of the model: how does it
responds to increasing stimuli strength or how is it modulated by an
increase in external background activity. We found that, while the
firing response scales linearly the response in terms of membrane
potential variations over the population exhibits a strong
suppression. We then embed this local network description in a ring
geometry to describe the spatial integration across the neocortical
sheet. We first show that this simple model accurately predicts the
emergence of propagating waves in response to simple stimuli
[[cite:Muller2014]].

Finally we re-construct a typical experimental paradigm of multi-input
integration in visual processing: the apparent motion protocol. We
compare the model's response to optical imaging of spatio-temporal
dynamics in the primary visual cortex of fixating monkey (Chemla &
Chavane, unpublished observations). The model exhibited a similar
spatio-temporal pattern of suppression such as the one observed /in
vivo/, our study therefore proposes that the horizontal fib re network
combined with the strongly sublinear relation between membrane
potential deflection and activity in the local network appears as a
putative sufficient explanation for the observation found in VSDi
recordings during an apparent motion stimulus in fixating monkeys.


\normalfont

* Introduction 
\normalfont

Recent advances in imaging technique, in particular voltage-sensitive
dye imaging (VSDi), have revealed fundamental properties of
neocortical processing
[[cite:Arieli1996,Contreras2001,Petersen2001,Ferezou2006,Civillico2012]]:
subthreshold responses to sensory inputs are locally homogeneous in
primary sensory areas, depolarizations tend to spread across spatially
neighboring regions and responses to sensory stimuli are strongly
affected by the level of ongoing activity. It also appears as great
tools to unveil how the spatio-temporal dynamics in the neocortex
shape canonical cortical operations such as normalization
[[cite:Reynaud2012]].

On the other hand, the literature lacks, to the best of our
knowledge, theoretical models that provides a detailed account of
those phenomena with a clear relation between how this signal is
generated and those physiological phenomena at that spatial scale
(i.e. at the millimeters or centimeters scale). Detailed model of a
neocortical column (i.e. \(\sim\)0.5mm^2 scale) have been recently
proposed, see [[citetext:Chemla2010]] for the link with the VSDi signal or
more generally [[citetext:Markram2015]], but their computational cost
impedes the generalization to higher spatial scale. The aim of the
present communication is thus to design a theoretical model of
neocortical dynamics with the following properties: 1) it should
operate at the temporal and spatial scales of optical imaging and 2)
it should have a correlate in terms of single-cell dynamics (in
particular membrane potential dynamics), so that the model can
directly generate predictions for the signal imaged by the VSDi
technique [[cite:Berger2007]].

More specifically, our study focuses on network dynamics in
/activated/ cortical states, thus the desired model should describe
neocortical computation in the asynchronous regime, where cortical
activity is characterized by irregular firing and strong subthreshold
fluctuations at the neuronal level [[cite:Steriade2001,Destexhe2003]]. The
strategy behind the present model is to take advantage of the
/mean-field/ descriptions of network dynamics in this regime. Via
self-consistent approaches, those descriptions allow to capture the
dynamical properties of population activity in recurrent networks
[[cite:Amit1997,Brunel1999,Brunel2000,Latham2000,ElBoustani2009]]. The
present model thus relies on the following scheme: 1) we consider the
randomly connected network of 10000 neurons as a unit to describe a
cortical column and 2) we embedded the analytical description of this
cortical column model into a ring geometry with physiological local
connectivity profiles to model spatio-temporal integration on the
neocortical sheet.

A prerequisite was therefore to establish the accuracy of the
analytical description of the cortical column model. This is the focus
of the first part of this paper: by comparing analytical prediction of
the model with numerical simulations, we can precisely evaluate the
accuracy and/or weaknesses of the analytical description to evaluate
its potential impact on the modeling of the network.

The second part of the paper investigates the integrative properties
of the model, i.e. the relation between the network response and the
properties of the input. Finally we compare the model prediction with
VSDi recordings in awake behaving monkey in a stereotypical paradigm
of visual processing: the apparent-motion protocol.

* Material and Methods
\small

We describe the equations and parameters used for the neuronal,
synaptic and network modeling. We present our /heuristic/ treatment of
the neuronal /transfer functions/: the quantity that accounts for the
cellular computation in /mean-field/ models of population
activity. Then, we present the specific markovian model of population
activity used in this study. Finally, we embed this description of
local population dynamics in a ring model to describe spatio-temporal
integration on the neocortical sheet.

** Single neuron models

The neuronal model used in this study is the adaptative exponential
and fire (AdExp) model [[cite:Brette2005a]]. The equation for the membrane
potential and the adaptation current therefore reads:

#+NAME: eq:iAdExp
\begin{equation}
  \left\{
  \begin{split}
  & C_m\,\frac{dV}{dt} = g_{L} \,(E_{L}-V) + I_{syn}(V,t) + k_a e^{\frac{V - V_{thre} }{k_a}}- I_w \\
  & \tau_w \frac{d I_w}{dt} = - I_w + \sum_{t_s \in \{t_{spike}\}} b \, \, \delta (t-t_s)
  \end{split}
\right.
\end{equation}

where $I_{syn}(V, t)$ is the current emulating synaptic activity that
will create the fluctuations, $I_w$ reproduces the I_m current
[[cite:McCormick1985]]. The spiking mechanism is the following: when
$V(t)$ reaches \(V_{thre}+5 \, k_a \), this triggers a spike t_s \in
\{t_{spike}\}, this increases the adaptation variable $I_w$ by \(b\),
the membrane potential is then clamped at \(E_L\) for a duration
\tau_{refrac}=5ms. We consider two versions of this model: a regular
spiking neuron for the excitatory cells and a fast spiking neuron for
the inhibitory cells (see Figure [[fig:tf]]). The parameters of those two
models can be found on Table [[table:params]].

#+ATTR_LATEX: :float multicolumn
#+NAME: table:params
#+CAPTION: *Model parameters*. 
| *Parameters*          | Parameter Name                 | Symbol            | Value | Unit |
|-----------------------+--------------------------------+-------------------+-------+------|
| /                     | <>                             | <>                |    <> | /    |
|                       |                                |                   |       |      |
| *cellular properties* |                                |                   |       |      |
|                       | leak conductance               | \(g_L\)           |    10 | nS   |
|                       | leak reversal potential        | \(E_L\)           |   -65 | mV   |
|                       | membrane capacitance           | \(C_m\)           |   150 | pF   |
|                       | leak reversal potential        | \(E_L\)           |   -65 | mV   |
|                       | AP threshold                   | \(V_{thre}\)      |   -50 | mV   |
|                       | refractory period              | \(\tau_{refrec}\) |     5 | ms   |
|                       | adaptation time constant       | \(\tau_w\)        |   500 | ms   |
| *excitatory cell*     |                                |                   |       |      |
|                       | sodium sharpness               | \(k_a\)           |     2 | mV   |
|                       | adaptation current increment   | \(b\)             |    20 | pA   |
|                       | adaptation conductance         | \(a\)             |     4 | nS   |
| *inhibitory cell*     |                                |                   |       |      |
|                       | sodium sharpness               | \(k_a\)           |   0.5 | mV   |
|                       | adaptation current increment   | \(b\)             |     0 | pA   |
|                       | adaptation conductance         | \(a\)             |     0 | nS   |
| *synaptic properties* |                                |                   |       |      |
|                       | excitatory reversal potential  | \(E_e\)           |     0 | mV   |
|                       | inhibitory reversal potential  | \(E_i\)           |   -80 | mV   |
|                       | excitatory quantal conductance | \(Q_e\)           |     1 | nS   |
|                       | inhibitory quantal conductance | \(Q_i\)           |     5 | nS   |
|                       | excitatory decay               | \(\tau_e\)        |     5 | ms   |
|                       | inhibitory  decay              | \(\tau_i\)        |     5 | ms   |
| *numerical network*   |                                |                   |       |      |
|                       | cell number                    | \(N_{tot}\)       | 10000 |      |
|                       | connectivity probability       | \(\epsilon\)      |    5% |      |
|                       | fraction of inhibitory cells   | g                 |   20% |      |
|                       | external drive                 | \(\nu_e^{drive}\) |     4 | Hz   |
| *ring model*          |                                |                   |       |      |
|                       | total extent                   | \(L_{tot}\)       |    40 | mm   |
|                       | excitatory connectivity extent | \(l_{exc}\)       |     5 | mm   |
|                       | inhibitory connectivity extent | \(l_{inh}\)       |     1 | mm   |
|                       | propagation delay              | \(v_c\)           |   300 | mm/s |

** Synaptic model

The time- and voltage-dependent current that stimulate the neuron is
made of the sum of an excitatory and inhibitory currents (indexed by
\(s \in \{e,i\}\) and having a reversal potential \(E_s\)):

#+NAME: eq:syn-current
\begin{equation}
 I_{syn}(V,t) = \sum_{s \in \{e,i\}} \sum_{t_s \in \{t_s\}} Q_s \, e^{-\frac{t}{\tau_s}} \, (E_{s}-V) \, \mathcal{H}(t-t_s)
\end{equation}
where \(\mathcal{H}\) is the Heaviside function.

This synaptic model is referred to as the /conductance-based
exponential/ synapse. The set of events \(\{t_e\}\) and \(\{t_i\}\)
are the set of excitatory and inhibitory events arriving to the
neuron. In numerical simulations of single neurons, it will be
generated by stationary Poisson processes. In numerical simulations of
network dynamics it will correspond to the set of spike times of the
neurons connecting to the target neurons, both via recurrent and
feedforward connectivity.

** Numerical network model

#+ATTR_LATEX: :width .5\linewidth
#+NAME: ntwk-architect
#+CAPTION: *Schematic of the local network architecture*. The network is made of \(N_e=(1-g) \, N_{tot}\) excitatory and \(N_i=g \, N_{tot}\) inhibitory neurons. All excitatory connections (afferent and recurrent) onto a neuron corresponds to \(K_e= \epsilon \, (1-g) \, N_{tot}\) synapses of weight \(Q_e\). All inhibitory connections (afferent and recurrent) onto a neuron corresponds to \(K_i= \epsilon \, g \, N_{tot}\) synapses of weight \(Q_i\)
[[../figures/architext-ntwk.png]]

All simulations of numerical network were performed with the =brian2=
simulator [[cite:Goodman2009]], see [[http://brian2.readthedocs.org]]. For all
simulations, the network was composed of \(N_{tot}\)=10000 neurons,
separated in two populations, one excitatory and one inhibitory with a
ratio of g=20% inhibitory cells. Those two populations we recurrently
connected (internally and mutually) with a connectivity probability
\(\epsilon\)=5%.

Because this network did not display self-sustained activity (see
Figure [[fig:phase-space]], in contrast to [[citetext:Vogels2005]]), an
excitatory population exerted an /external drive/ to bring the network
out of the quiescent state. This population targeted both the
excitatory and inhibitory neurons. Note that the firing rate of this
population was linearly increased to avoid a too strong initial
synchronization (see Figure [[fig:ntwk-act]]). Finally, an excitatory
population of time varying firing rate could was added to evoke
activity transients in the population dynamics. This last stimulation
targeted only the excitatory population. The number of neurons in
those two excitatory populations was taken as identical to the number
of excitatory neurons (i.e. \((1-g)\,N_{tot}\)) and created synapses
onto the recurrent network with the same probability
\(\epsilon\). After temporal discretization, the firing rates of those
afferent populations were converted into spikes by using the
properties of a Poisson process (i.e. eliciting a spike at \(t\) with
a probability \(\nu(t) \,dt \)). All simulations were performed with a
time-step dt=0.1ms.

** Estimating the transfer functions of single neurons

The transfer function \(\mathcal{F}\) of a single neuron is defined
here as the function that maps the value of the stationary excitatory
and inhibitory presynaptic release frequencies to the output
stationary firing rate response, i.e. \(\nu_{out} = \mathcal{F}(\nu_e,
\nu_i)\). Note the stationary hypothesis in the definition of the
transfer function (see discussion in main text).

Because an analytical solution of this function for the single neuron
models considered in our study is a very challenging mathematical
problem, we adopted a semi-analytical approach. We performed numerical
simulations of single cell dynamics at various excitatory and
inhibitory presynaptic frequencies (\(\nu_e\) and \(\nu_i\)
respectively) (see the output in Figure [[fig:tf]]) on which we fitted the
coefficients of an analytical template to capture the single cell
model's response.

The procedure relied on fitting a /phenomenological threshold/
\(V_{thre}^{eff}\) that accounts for the single neuron non-linearities
(spiking and reset mechanism, adaptation mechanisms) on top of the
subthreshold integration effects [[cite:Zerlaut2016]]. This
phenomenological threshold is then plugged-in into the following
formula (analogous to [[citetext:Amit1997]]) to become our firing response
estimate:

#+NAME: eq:template
\begin{equation}
  \nu_{out} = \frac{1}{2\,\tau_V} \cdot 
  {Erfc}(\frac{V_{thre}^{eff}-\mu_V}{\sqrt{2} \, \sigma_V})
\end{equation}

Where \( (\mu_V, \sigma_V, \tau_V) \) are the mean, standard deviation
and autocorrelation time constant of the membrane potential
fluctuations. How to calculate those quantities as a response to a
stationary stimulation is the focus of the next section.

The phenomenological threshold was taken as a second order polynomial
in the three dimensional space \( (\mu_V, \sigma_V, \tau_V) \):

#+NAME: eq:quadratic-threshold
\begin{equation}
  \begin{split}
   V_{thre}^{eff} & (\mu_V, \sigma_V, \tau_V^N) = P_0 + 
   \sum_{x \in \{ \mu_V, \sigma_V, \tau_V^N\}} P_x \cdot \Big(  \frac{x - x^0}{\delta x^0} \Big) + \\
   & \sum_{ x,y \in \{ \mu_V, \sigma_V, \tau_V^N\}^2} P_{xy} \cdot
   \Big( \frac{x - x^0}{\delta x^0}  \Big) \,  \Big( \frac{y - y^0}{\delta y^0} \Big)
 \end{split}
\end{equation}

Where the normalization factors \(\mu_V^0\)=-60mV, \(\delta
\mu_V^0\)=10mV, \(\sigma_V^0\)=4mV, \(\delta \sigma_V^0\) = 6mV,
\(\tau_V^{N0}\)=0.5 and \(\delta \tau_V^{N0}\)= 1 arbitrarily delimits
the /fluctuation-driven/ regime (a mean value $x$ and an extent
$\delta x$, \(\forall x \in \{\mu_V, \sigma_V, \tau_V^N\}\)).  They
render the fitting of the phenomenological threshold easier, as they
insure that the coefficients take similar values. It is kept constant
all along the study. The phenomenological threshold was taken as a
second order polynomial and not as a linear threshold, for two
reasons: 1) unlike in an experimental study [[cite:Zerlaut2016]], we are
not limited by the number of sampling points, the number of fitted
coefficients can thus be higher as the probability of overfitting
becomes negligible 2) it gives more flexibility to the template,
indeed the linear threshold was found a good approximation in the
/fluctuation-driven/ regime, i.e. when the diffusion approximation
holds, however, for low values of the presynaptic frequencies, we can
be far from this approximation, the additional coefficients are used
to capture the firing response in those domains.


The fitting procedure was identical to [[citetext:Zerlaut2016]], it
consisted first in a linear regression in the phenomenological
threshold space of Equation [[eq:quadratic-threshold]], followed by a
non-linear optimization of Equation [[eq:template]] on the firing rate
response. Both fitting were performed with the =leastsq= method in the
=optimize= package of =SciPy=.

** Calculus of the subthreshold membrane potential fluctuations

Here, we detail the analytical calculus that translate the input to
the neuron into the properties of the membrane potential
fluctuations. The input is made of two Poisson shotnoise: one
excitatory and one inhibitory that are both convoluted with an
exponential waveform to produce the synaptic conductances time
courses.

*** Conductances fluctuations

From Campbell's theorem [[cite:Papoulis1991]], we first get the mean
(\(\mu_{Ge}, \mu_{Gi}\)) and standard deviation (\(\sigma_{Ge},
\sigma_{Gi}\)) of the excitatory and inhibitory conductance
fluctuations:

\begin{equation}
\begin{split}
& \mu_{Ge}(\nu_e, \nu_i) = \nu_e \, K_e \, \tau_e \, Q_e \\
& \sigma_{Ge}(\nu_e, \nu_i) = \sqrt{\frac{\nu_e \, K_e \, \tau_e}{2}} \, Q_e \\
& \mu_{Gi}(\nu_e, \nu_i) = \nu_i \, K_i \, \tau_i \, Q_i \\
& \sigma_{Gi}(\nu_e, \nu_i) = \sqrt{\frac{\nu_i \, K_i \, \tau_i}{2}} \, Q_i 
\end{split}
\end{equation}

The mean conductances will control the input conductance of the neuron
\(\mu_G\) and therefore its effective membrane time constant
\(\tau_m\):

\begin{equation}
\begin{split}
& \mu_{G}(\nu_e, \nu_i) = \mu_{Ge} + \mu_{Gi} + g_L \\
& \tau_m(\nu_e, \nu_i) = \frac{C_m}{\mu_{G}}
\end{split}
\end{equation}

*** Mean membrane potential

Following [[citetext:Kuhn2004]], the mean membrane potential is obtained
by taking the stationary solution to static conductances given by the
mean synaptic bombardment (for the passive version of Equation
[[eq:iAdExp]], i.e. removing the adaptation and spiking mechanisms). We
obtain:

#+NAME: eq:mu-v
\begin{equation}
\mu_V(\nu_e, \nu_i) = \frac{\mu_{Ge} \, E_e + \mu_{Gi} \, E_i + g_L \, E_L}{\mu_{G}}
\end{equation}

We will now approximate the driving force \(E_s - V(t)\) of synaptic
events by the level resulting from the mean conductance bombardment:
\(E_s - \mu_V\). This will enable an analytical solution for the
standard deviation \( \sigma_V\) and the autocorrelation time \(
\sigma_V\) of the fluctuations.

*** Power spectrum of the membrane potential fluctuations

Obtaining \( \sigma_V\) and \(\tau_V\) is achieved by computing the
power spectrum density of the fluctuations. In the case of Poisson
processes, the power spectrum density of the fluctuations resulting
from the sum of events \(PSP_{s}(t)\) at frequency \(K_{s} \, \nu_s\)
can be obtained from shotnoise theory [[cite:Daley2007]]:

\begin{equation}
 P_V(f)  = \sum_{s \in \{e,i\}} K_s \, \nu_{s} \, \| \hat{\mathrm{PSP}_s}(f) \|^2
\end{equation}

where \(\hat{\mathrm{PSP}_s}(f)\) is the Fourier transform of the
time-varying function \(\mathrm{PSP}(t)\). Note that the relations
presented in this paper rely on the following convention for the
Fourier transform: \( \hat{F}(f) = \int_\mathbb{R} F(t) \, e^{- 2 i
\pi f t} \, dt\).

After fixing the driving force to \(E_s - \mu_V\), the equation for a
 post-synaptic membrane potential event \(s\) around \(\mu_V\) is

\begin{equation}
 \tau_m \frac{d \, \mathrm{PSP}_s }{dt} + \mathrm{PSP}_s = U_s \, \mathcal{H}(t) \, e^{\frac{-t}{\tau_s}}
\end{equation}

where \( U_s = \frac{Q_s}{\mu_G} (E_s - \mu_V) \) and \(
\mathcal{H}(t) \) is the Heaviside function.

Its solution is:

\begin{equation}
\mathrm{PSP}_s(t)  = U_s \, \frac{\tau_s}{\tau_m - \tau_s} \, \big( 
e^{\frac{-t}{\tau_m}} - e^{\frac{-t}{\tau_s}} \big) \, \mathcal{H}(t)
\end{equation}

We take the Fourier transform:

\begin{equation}
\hat{\mathrm{PSP}_s}(f) = U_s \, \frac{\tau_s}{\tau_m - \tau_s} \, 
\big(
\frac{\tau_{m}}{2 \, i  \,  \pi \, f \, \tau_{m} +1} 
- \frac{\tau_s}{2 \, i  \,  \pi \, f \, \tau_s +1} \big)
\end{equation}

We will need the value of the square modulus at \(f=0\):

#+NAME: eq:psp0
\begin{equation}
\| \hat{\mathrm{PSP}}(0) \|^2 = (U_s \cdot \tau_s)^2
\end{equation}

As well as the integral of the square modulus:

#+NAME: eq:psp-int
\begin{equation}
\int_\mathbb{R}  df \, \| \hat{\mathrm{PSP}}(f) \|^2 = \frac{(U_s \cdot \tau_s)^2}{2 \, (\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) }
\end{equation}

*** Standard deviation of the fluctuations

The standard deviation follows:

\begin{equation}
 (\sigma_V)^2  = \int_\mathbb{R}  df \, P_V(f)
\end{equation}

Using Equation [[eq:psp-int]], we find the final expression for \(\sigma_V\):

#+NAME: eq:sigma-v
\begin{equation}
 \sigma_V(\nu_e, \nu_i)  = \sqrt{ \sum_s K_s \, \nu_s \, \frac{(U_s \cdot \tau_s)^2}{2 \, (\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) } }
\end{equation}

*** Autocorrelation-time of the fluctuations

We defined the global autocorrelation time as [[cite:Zerlaut2016]]:

\begin{equation}
  \tau_V = \frac{1}{2} \, \big( \frac{\int_\mathbb{R} P_V(f) \, d f}{ P_V(0) } \big)^{-1}
\end{equation}

Using Equations [[eq:psp-int]] and [[eq:psp0]], we find the final expression
for \(\tau_V\):

#+NAME: eq:tau-v
\begin{equation}
  \tau_V(\nu_e, \nu_i) = \Big( \frac{
  \sum_s \big( K_s \, \nu_s \, (U_s \cdot \tau_s)^2\big) 
  }{
  \sum_s \big( K_s \, \nu_s \, (U_s \cdot \tau_s)^2 /(\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) \big)
  } \Big)
\end{equation}

Therefore the set of Equations [[eq:mu-v]], [[eq:sigma-v]] and [[eq:tau-v]]
translate the presynaptic frequencies into membrane fluctuations
properties \(\mu_V, \sigma_V, \tau_V\).

The previous methodological section allowed to translate the
fluctuations properties \(\mu_V, \sigma_V, \tau_V\) into a spiking
probability thanks to a minimization procedure. The combination of the
present analytical calculus and the previous fitting procedure (on
numerical simulations data) constitute our semi-analytical approach to
determine the transfer function of a single cell model: \( \nu_{out} =
\mathcal{F}(\nu_e, \nu_i)\).

** Master equation for local population dynamics

An analytical description of the cellular transfer function is the
core of theoretical descriptions of asynchronous dynamics in sparsely
connected random networks [[cite:Amit1997,Brunel2000,Renart2004]].

Because we will investigate relatively slow dynamics
(\(\tau\)>25-50ms) (and because of the stationary formulation of our
transfer function), we will use the Markovian description developed
in [[citetext:ElBoustani2009]], it describes network activity at a time
scale \(T\), for which the network dynamics should be Markovian. The
choice of the time-scale \(T\) is quite crucial in this formalism, it
should be large enough so that activity can be considered as
memoryless (e.g. it can not be much smaller than the refractory
period, that would introduce memory effects) and small enough so that
each neuron can fire statistically only once per time interval
\(T\). Following [[citetext:ElBoustani2009]], we will arbitrarily take
\(T\)=5ms all along the study as it offers a good compromise between
those two constraints. 


The formalism describes the first and second moments of the population
activity for each populations. We consider here two populations: one
excitatory and one inhibitory, the formalism thus describes the
evolution of five quantities: the two means \(\nu_e(t)\) and
\(\nu_i(t)\) of the excitatory and inhibitory population activity
respectively (the instantaneous population firing rate, i.e. after
binning in bins of \(T\)=5ms, see discussion in
[[citetext:ElBoustani2009]]), the two variances \(c_{ee}(t)\) and
\(c_{ii}(t)\) of the the excitatory and inhibitory population activity
respectively and the covariance \(c_{ei}(t)\) between the excitatory
and inhibitory population activities. The set of differential
equations followed by those quantities reads [[cite:ElBoustani2009]]:

#+NAME: eq:master-equation
\begin{equation}
\left\{
\begin{split}
T \, \frac{\partial \nu_\mu}{\partial t} = & (\mathcal{F}_\mu - \nu_\mu )
   + \frac{1}{2} \, c_{\lambda \eta} \, 
\frac{\partial^2 \mathcal{F}_\mu}{\partial \nu_\lambda \partial \nu_\eta} \\
T \, \frac{\partial c_{\lambda \eta} }{\partial t}  =  & A_{\lambda \eta} +
(\mathcal{F}_\lambda - \nu_\lambda ) \, (\mathcal{F}_\eta - \nu_\eta ) + \\
 & c_{\lambda \mu} \frac{\partial \mathcal{F}_\mu}{\partial \nu_\lambda} +
 c_{\mu \eta} \frac{\partial \mathcal{F}_\mu}{\partial \nu_\eta} 
 - 2  c_{\lambda \eta}
\end{split}
\right.
\end{equation}

with:
\begin{equation}
A_{\lambda \eta} =  
\left\{
\begin{split}
\frac{\mathcal{F}_\lambda \, (1/T - \mathcal{F}_\lambda)}{N_\lambda} 
\qquad & \textrm{if  } \lambda=\eta \\
0 \qquad & \textrm{otherwise}
\end{split}
\right.
\end{equation}

Note that, for the concision of the expressions, we used Einstein's
index summation convention: if an index is repeated in a product, a
summation over the whole range of value is implied (e.g. we sum over
\(\lambda \in \{e,i\} \) in the first equation, note that,
consequently, \(\lambda\) does not appear in the left side of the
equation). Also the dependency of the firing rate response to the
excitatory and inhibitory activities has been omitted: yielding
\(\mathcal{F}_\mu\) instead of \(\mathcal{F}_\mu(\nu_e,\nu_i)\),
\(\forall \mu \in \{e,i\} \).

We will also use the reduction to first order of this system (for the
phase-space analysis, see Results). This yields:

#+NAME: eq:master-eq-1st-order
\begin{equation}
T \, \frac{\partial \nu_\mu}{\partial t} = \mathcal{F}_\mu - \nu_\mu \\
\end{equation}

** Ring model 

We now embed the previous markovian description of population dynamics
in a ring geometry to model spatio-temporal integration on the
neocortical sheet. The ring geometry corresponds to a one dimensional
spatial description with an invariance by translation, i.e. for all
quantities \(f\), \(f(x)=f(x+L)\)(also termed one dimensional periodic
boundary conditions), where \(L\) is the length of the ring model. For
simplicity, we consider here only the first moments of the
second-order description: i.e. the means of the excitatory and
inhibitory population activities: \(\nu_e(t)\) and \(\nu_i(t)\)
respectively.

We introduce the Gaussian connectivity profiles (see Figure
[[fig:simple-stim]]) that defines the connectivity across cortical columns
(i.e. local networks described in the previous section):

\begin{equation}
\mathcal{N}_e(x) = \frac{1}{\sqrt{2 \pi} l_{exc}} e^{-(\frac{x}{\sqrt{2} l_{exc}})^2} \quad ; \quad 
\mathcal{N}_i(x) = \frac{1}{\sqrt{2 \pi} l_{inh}} e^{-(\frac{x}{\sqrt{2} l_{inh}})^2}
\end{equation}

where \(l_{exc}\) and \(l_{inh}\) are the excitatory and inhibitory
extent of the connectivity profiles respectively.

We also introduce the effect of a finite axonal conduction speed
\(v_c\), this will introduce delays for the propagation of activity
across cortical columns: for a network at a distance \(x\), the
afferent activity will arrive delayed by \(x/v_c\).

Finally, the equations that govern the activity in space and time are
given by:

\begin{equation}
\left\{
\begin{split}
\nu_e^{input}(x,t) = &\nu_e^{drive}  + 
\int_\mathbb{R} dy \, \mathcal{N}_e(x-y) \, \nu_e(y, t-\|y-x\|/v_c) \\
\nu_i^{input}(x,t) = & \int_\mathbb{R} dy \, \mathcal{N}_i(x-y) \, \nu_i(y, t-\|y-x\|/v_c) \\
T \frac{\partial \nu_e(x,t)}{\partial t} = & -  \nu_e(x,t) + \\
& \mathcal{F}_e(\nu_e^{aff}(x,t)+\nu_e^{input}(x,t), \nu_i^{input}(x,t) ) \\
T \frac{\partial \nu_i(x,t)}{\partial t} = & -  \nu_i(x,t) + \mathcal{F}_i(\nu_e^{input}(x,t), \nu_i^{input}(x,t) )
\end{split}
\right.
\end{equation}

where \(\nu_e^{drive}\) is the external drive and \(\nu_e^{aff}(x,t)\)
is the afferent (thalamic) stimulation.

The local correlate in terms of mean membrane potential \(\mu_V(x,t)\)
is given by Equation [[eq:mu-v]].

** Afferent stimulation 

In the case of the local population model, the afferent input was
chosen as a piecewise double Gaussian waveform:

#+NAME: eq:input
\begin{equation}
\nu_e^{aff}(t) = A \, \Big(
e^{-(\frac{t-t_0}{\sqrt{2} \tau_1})^2} \mathcal{H}(t_0-t)+
e^{-(\frac{t-t_0}{\sqrt{2} \tau_2})^2} \mathcal{H}(t-t_0)
\Big)
\end{equation}

Thus, we independently control: 1) the maximum amplitude \(A\) of the
stimulation, its rising time constant \(\tau_1\) and its decay time
constant \(\tau_2\).

In the case of the ring model, this temporal waveform was multiplied
by a Gaussian profile in space of extent \(l_{stim}\) to yield the
waveform:

#+NAME: eq:ring-input
\begin{equation}
\nu_e^{aff}(x,t)) = A \, e^{-(\frac{x-x_0}{\sqrt{2} l_{stim}})^2}
\, \Big(
e^{-(\frac{t-t_0}{\sqrt{2} \tau_1})^2} \mathcal{H}(t_0-t)+
e^{-(\frac{t-t_0}{\sqrt{2} \tau_2})^2} \mathcal{H}(t-t_0)
\Big)
\end{equation}

* Results
\normalsize

The results are organized as follows. We first construct the
analytical model that will describe the dynamics of a single cortical
column. In particular, we describe the semi-analytical workflow that
enables the derivation of the cellular transfer function: the core of
the population model. Next, we investigate whether the analytical
description accurately describe population dynamics by comparing its
prediction to numerical simulations. Then, we investigate the
integrative properties of the network model. Finally we embed the
cortical column model into a ring model and we compare its predictions
to VSDi recordings in the visual cortex of awake behaving monkey.

** Modeling a single cortical column

#+ATTR_LATEX: :float multicolumn :width .7\linewidth
#+NAME: fig:tf
#+CAPTION: *Single cell models of the excitatory and inhibitory populations.* Top: response to a current step of 200pA lasting 300ms. Bottom: /transfer function/ of the single cell, i.e. output firing rate as a function of the excitatory (x-axis) and inhibitory (color-coded) presynaptic release frequencies. Note that the range of the excitatory and frequencies assumes numbers of synapses (\(K_e\)=40 and \(K_i\)=10 for the excitation and inhibition respectively).  *(A)* Excitatory cells. Note the presence of spike-frequency adaptation and subthreshold adaptation. *(B)* Inhibitory cells. Note the very narrow spike initiation dynamics (\(k_a\)=0.5mV). Also, note the steepest relation to excitation (with respect to the excitatory cell) at various inhibitory levels as a result of the increased excitability as a result of the increased excitability of the inhibitory cell (with respect to the excitatory cell).
[[../figures/tf.png]]



Because optical imaging presumably sample most of its signals from
superficial layers, we model here the layer II/III network: it is
characterized by a strong recurrent connectivity and an important
cellular diversity, in particular one finds many types of interneurons
[[cite:Markram2004,Ascoli2008a]]. We adopt here a very simplistic
description of this network, it is made of two neuronal population:
one excitatory and one inhibitory comprising 8000 and 2000 neurons
respectively. All neurons within the two population synaptically
interconnect randomly to each other with a connectivity probability of
5%. The excitatory and inhibitory cells have the same passive
properties. We nonetheless include an asymmetry between the excitatory
and inhibitory populations: because the inhibitory population includes
Fast-Spiking cells that can exhibit very high firing frequencies
[[cite:Markram2004]], we set its spiking mechanism sharper (more precisely
its sodium activation activation curve is steeper, see Methods) than
that of excitatory cells, additionally we add a strong spike-frequency
adaptation current in excitatory cells that is absent in inhibitory
cells. Those two effects render the inhibitory neurons more excitable
(see the different responses to the same current step in Figure
[[fig:tf]]). All parameters of the cortical column can be found in Table
[[table:params]].

** A Markovian model to describe population dynamics

We now want to have an analytical description of the collective
dynamics of this local network. We adopted the formalism presented in
[[citetext:ElBoustani2009]]. Two reasons motivated this choice: 1) because
10000 neurons is still far from the large network limit, finite-size
effects could have a significant impact on the dynamics and 2) because
of the relative complexity of the cellular models, an analytic
treatment of the type [[citetext:Amit1997]] is, to our knowledge, not
accessible and would be extremely challenging to derive. The Markovian
framework proposed in [[citetext:ElBoustani2009]] positively respond to
those two constraints: it is a second-order description of population
activity that describes fluctuations emerging from finite-size effects
and it is applicable to any neuron model as long as its transfer
function can be characterized. In a companion study [[cite:Zerlaut2016]],
we developed a semi-analytical approach to characterize those
transfer functions (see next section), we will therefore incorporate
this description into the formalism.

Nonetheless, the study of [[citetext:ElBoustani2009]] only investigated
the ability of the formalism to describe 1) the stationary point of
the network activity and 2) in a situation where the neuronal models
models had an analytic estimate for the transfer function
(current-based integrate-and-fire model). Investigating whether this
description generalizes to transient dynamics and transfer functions
estimated with a semi-analytical approach is investigated in the next
sections.

** Transfer functions of excitatory and inhibitory cells

We briefly describe here the semi-analytical approach used to
characterize the transfer function (see details in the Methods).

The transfer function \(\mathcal{F}\) of a single neuron is defined
here as the function that maps the value of the stationary excitatory
and inhibitory presynaptic release frequencies to the output
stationary firing rate response, i.e. \(\nu_{out} = \mathcal{F}(\nu_e,
\nu_i)\). This kind of input-output functions lie at the core of
/mean-field/ models of population dynamics, reviewed in
[[citetext:Renart2004]] and is consequently the main ingredient of the
formalism adopted here [[cite:ElBoustani2009]]. Note here that the
formulation of the transfer function imply a stationary hypothesis:
both for the input (stationary Poisson processes) and the output
firing (a stationary firing rate). We will study in the following what
are the limitations introduced by this stationary hypothesis in the
description of the temporal dynamics of network activity.

In a previous communication [[cite:Zerlaut2016]], we found that the firing
rate response of several models (including the adaptative exponential
integrate and fire considered in this study) would be captured by a
/fluctuations-dependent/ threshold in a simple approximation of the
firing probability (see Methods).

The semi-analytical approach thus consisted in making numerical
simulations of single-cell dynamics for various presynaptic activity
levels (i.e. scanning various \(\nu_e, \nu_i\) configurations) and
measuring the output firing rate \(\nu_{out}\). All those
configurations corresponded to analytical estimates of
\((\mu_V,\sigma_V,\tau_V)\), we then fitted the
/fluctuations-dependent/ threshold that bring the analytical estimate
to the measured firing response. This procedure resulted in the
analytical estimates shown in Figure [[fig:tf]] and compared with the
results of numerical simulations.

** Spontaneous activity in the cortical column

#+ATTR_LATEX: :float multicolumn :width .7\linewidth
#+NAME: fig:phase-space
#+CAPTION: *Using the analytical description to look for a stable configuration of spontaneous network activity.* Phase space of the dynamical system resulting from the first order of the markovian description, shown for two levels of external excitatory drive \(\nu_e^{drive}\). The lines represents trajectories resulting from different initial conditions. The vector field correspond to the time-evolution operator (the arrows represent the direction in the two-dimensional space and the color codes for the norm of the vector). *(A)* Phase space in the absence of an external drive \(\nu_e^{drive}\)=0Hz, the stable fixed point of the dynamics correspond to the quiescent network state \(\nu_e=\nu_i\)=0Hz. *(A)* Phase space with an external drive \(\nu_e^{drive}\)=4Hz, the stable fixed point of the dynamics correspond now corresponds to an active state with asymmetric activity levels: \(\nu_e\)=1.6Hz and \(\nu_i\)=8.9Hz (round marker). 
[[../figures/finding_fixed_point.png]]

#+ATTR_LATEX: :width .7\linewidth
#+NAME: fig:ntwk-act
#+CAPTION: *Numerical simulations of the dynamics of a recurrent network of 10000 neurons (see parameters in Table [[table:params]])*. Note that all plots have the same x-axis: time. *(A)* Sample of the spiking activity of 500 neurons (green, 400 excitatory and red, 100 inhibitory). *(B)* Population activity (i.e. spiking activity sampled in 5ms time bins across the population) of the excitatory (green) and inhibitory (red) sub-populations. We also show the applied external drive (\(\nu_e^{drive}(t)\), black line), note the slow linear increase to reach \(\nu_e^{drive}\)=4Hz and try to reduce the initial synchronization that would result from an abrupt onset. *(C)* Membrane potential (top) and conductances (bottom, excitatory in green and inhibitory in red) time courses of three randomly chosen inhibitory neurons. *(D)* Membrane potential and conductances time courses of three randomly chosen excitatory neurons.
[[../figures/nwtk_activity.png]]


#+ATTR_LATEX: :width .8\linewidth
#+NAME: fig:mf-stat-pred
#+CAPTION: *Mean field prediction of the stationary activity.* Those quantities are evaluated after discarding the initial 500ms transient. *(A)* Gaussian predictions of the population activities (filled curve) compared to those observed in numerical simulations (empty bars). *(B)* Mean of the membrane potential and conductances time courses. Evaluated over 3 cells for the numerical simulations (empty bars, mean and standard deviation). *(C)* Standard deviation of membrane potential and conductances time courses.
[[../figures/mean_field_stat_pred.png]]

The combination of the transfer function and the markovian formalism
(Equation [[eq:master-equation]] in the Methods) yields our analytical
description of the layer II-III population dynamics in a single
cortical column.

We first use this analytical description to look for a physiological
configuration of spontaneous activity. There exists two qualitatively
different types of spontaneous asynchronous activity
[[cite:Vogels2005,Kumar2008]]: either the network is dominated by
inhibition and the network needs an asynchronous external excitatory
drive to exhibit spontaneous activity [[cite:Amit1997,Brunel2000]] or the
network exhibits an asynchronous self-sustained activity state and
just needs an initial "kick" to exit from the quiescent state
[[cite:Vogels2005,Kumar2008,ElBoustani2009]]. In the latter case, the
network is globally dominated by excitation and strong /shunting/
conductance effects prevents the network from an excitatory runaway
[[cite:Kuhn2004,Kumar2008]]. Those two behaviors are thus determined by
the membrane, synaptic and connectivity parameters. We therefore
investigate how the chosen network parameters in this study would
determine the qualitative nature of the spontaneous activity state.

In the case of a single electrophysiological type (e.g. excitatory and
inhibitory neurons taken as the same integrate-and-fire model), it was
shown that a simple /mean-field/ analysis allow to predict in which
situation the network parameters corresponds
[[cite:Brunel2000,Kumar2008]], here we generalized this approach to the
two populations considered in this study and we investigate the
behavior of our network model given the parameters of Table
[[table:params]]. To this purpose, we simplified the dynamical system
describing population activity (Equation [[eq:master-equation]]) to its
first order so that we get a two dimensional system describing the
population spiking activity \(\nu_e(t)\) and \(\nu_i(t)\). We then
plotted the vector field of the time evolution operator in the phase
space of the dynamical system direction and launched some trajectories
with different initial conditions (see Figure [[fig:phase-space]]). The
result of this analysis is that, in absence of external input
(\(\nu_e^{drive}\)=0Hz), the only fixed point of the system is the
quiescent state (see Figure [[fig:phase-space]]A). This prediction of the
mean-field analysis was indeed confirmed by numerical simulations,
whatever the initial external "kick", the activity rapidly decayed
(T<50ms) to the quiescent state.

We conclude that, given the parameters of Table [[table:params]], our
network model does not have the ability to self-sustain activity and
will need an external excitatory drive to exhibit spontaneous activity
(note that this is also consistently with recent /in vivo/
observations in mice visual cortex, see
[[citetext:Reinhold2015]]). Indeed, when raising the external drive, a
non-quiescent fixed point appears (see Figure [[fig:phase-space]]B for
\(\nu_e^{drive}\)=4Hz). Numerical simulations confirmed the existence
of such a fixed point at those levels of activity (see Figure
[[fig:ntwk-act]]).

The particularity of this stationary fixed-point is its asymmetry in
terms of population activity, it corresponds to \(\nu_e\)=1.6Hz and
\(\nu_i\)=8.9Hz (i.e. corresponding to a factor 5-6 between the their
respective firing rates). The origin of this asymmetry is very
naturally the asymmetry in electrophysiological properties as the
excitatory and inhibitory neurons sample statistically the same
recurrent and external input. This phenomena has been observed in
extracellular recordings in human cortex [[cite:Peyrache2012]], cells
categorized as Fast-Spiking (such as our inhibitory cells) were shown
to fire 6-7 times more than cells categorized as Regular-Spiking (such
as our excitatory cells), an asymmetry in excitabilities thus
naturally provides a putative explanation for this phenomena (rather
than specific circuitry).

** Accuracy of the description of the spontaneous activity state

We compare more closely the numerical simulation (Figure
[[fig:ntwk-act]]) to the prediction of the Markovian description.

First, we see that there is a transient period of \(\sim\) 400ms
resulting from the onset of the external drive (see Figure
[[fig:ntwk-act]]B-D), we will therefore evaluate stationary properties
after discarding the first 500ms of the simulation.

After this initial transient, the population activities (\(\nu_e\) and
\(\nu_i\)) fluctuates around the stationary levels (see Figure
[[fig:ntwk-act]]). The Markovian description predicts this phenomena as it
contains the impact of finite size effects (the network comprises
10000 neurons). In Figure [[fig:mf-stat-pred]]A, we can see that the
distributions of the excitatory and inhibitory population activities
are rather well predicted by the formalism (it slightly overestimates
the means of the population activities).

We also investigated whether the average neuronal and synaptic
quantities were well predicted by the Markovian formalism. Indeed, we
found a very good match for all quantities (see Figure
[[fig:mf-stat-pred]]B,C, mean and variance of membrane potential and
synaptic conductances). Only the standard deviation of the membrane
potential fluctuations was underestimated (Figure [[fig:mf-stat-pred]]C),
presumably because of residual synchrony in the dynamics whereas the
Markovian formalism assumes a purely asynchronous regime.

** Description of the response to time-varying input

#+ATTR_LATEX: :width .7\linewidth
#+NAME: fig:mf-temp-pred
#+CAPTION: *Network response to a time-varying input and associated prediction of the Markovian formalism.* For all plots, the x-axis corresponds to time. Shown after 500ms of initial stimulation. *(A)* Sample of the spiking activity of 500 neurons (green, 400 excitatory and red, 100 inhibitory). *(B)* Population activity (in 5ms bins) of the excitatory (green) and inhibitory (red) sub-populations. Superimposed is the mean and standard deviation over time predicted by the Markovian formalism. We also show the applied external stimulation (\(\nu_e^{aff}(t)\), dotted line). *(C)* Membrane potential time courses of three excitatory cells (green, top) and three inhibitory cells (red, bottom) with the prediction of the mean and standard deviation in time. *(D)* Conductance time courses of the six cells in *C* with the predictions of the fluctuations superimposed.
[[../figures/ntwk_time_varying.png]]

We now examine whether the formalism captures the response to
time-varying input. Here again, we set the input and examine the
response after 500ms of initial simulation to discard transient
effects.

We first choose an afferent input of relatively low frequency content
(\(\sim\) [5-20]Hz, \( \tau_1 \)=60ms and \( \tau_2 \)=100ms in
Equation [[eq:input]]). The afferent input waveform, formulated in terms
of firing rate, was translated into individual afferent spikes
targeting the excitatory population. The response of the network to
this input is shown in Figure [[fig:mf-temp-pred]] in comparison with the
prediction of the Markovian formalism. The excitatory population
activity raises and immediately entrains a raise of the inhibitory
population. The analytical description captures well the order of
magnitude of the deflection, it only slightly underestimates the peak
value (Figure [[fig:mf-temp-pred]]B). But the numerical simulations also
show a marked hyperpolarization after the stimulation, the return to
the baseline level happens only \(\sim\) 200-300 ms after the end of
the stimulus, and not immediately as predicted by the Markovian
framework. Here this strong hyperpolarization is the result of the
strong spike-frequency adaptation current that remains as a
consequence of the high activity evoked by the stimulus. In the
Markovian there is no memory of the previous activity and therefore
this phenomena can not be accounted for. This typically illustrates a
limitation of the analytical description provided here. Note that this
is not a fundamental limitation of the Markovian formalism, it is a
limitation of this version of the formalism, that contains only
variables related to the instantaneous activity (see Discussion).

#+ATTR_LATEX: :width .7\linewidth
#+NAME: fig:mf-freq-dep
#+CAPTION: *Limitations of the Markovian description in the frequency domain.* Response of the network (numerical simulation and analytical description) to sinusoidal stimulation of the form \(\nu_e^{aff} = 5\mathrm{Hz} \, \big(1-\cos(2 \pi f (t-t_0))\big)/2\). The stimulation was set on at \(t_0\)=500ms. The response was fitted by a function of the form  \(\nu(t) = A \, \big(1-\cos(2 \pi f (t-t_0) - \phi)\big)/2\). *(A)* Amplitude of the sinusoidal response (\(A\) in the fitted response) for various frequencies. *(B)* Phase shift of the sinusoidal response (\(\phi\) in the fitted response) for various frequencies.
[[../figures/freq_dep_of_network.png]]

To study more precisely the temporal validity of the formalism, we
modulated the network activity by sinusoidal input and compared the
response predicted by the analytical description.

The numerical simulations showed a marked resonance at
\(\sim\)50Hz. Given the relatively high strength (compared to the
external input) of the excitatory-inhibitory loop, the network is
close to a bifurcation toward oscillations that are typically in the
gamma range [[cite:Brunel2003]]. A sinusoidal input therefore amplifies
those frequencies [[cite:Ledoux2011]]. Because the individual excitatory
and inhibitory post-synaptic currents approximately match each other,
the theoretical study of [[citetext:Brunel2003]] would predict
oscillations at 50-60Hz (the bifurcation would be achieved by reducing
\(\tau_e\)), thus compatible with the present observation.

More importantly, the main insight of this analysis is to show that
the network can track very fast temporal variations in the input, even
at time scales smaller than the integration time constant of the
single neurons [[cite:VanVreeswijk1996]].  Recurrent neural networks
globally behave as low-pass filters (though see [[cite:Ledoux2011]] for a
detailed treatment of the appearance of resonances), but with a high
cutoff frequency compared to the frequency content of thalamic input
for classical artificial stimuli (e.g. in the visual system: drifting
gratings, supra-10ms flashes, etc...).

Leaving apart the failure of capturing the network resonance (that is
linked to this special configuration of synaptic parameters), we
conclude that in the frequency range that will be used in the
following (f<50-100Hz) the description of the formalism gives a
relatively accurate description of the network response in the sense
that it accurately predicts that there should not be a frequency
filtering within this range. Again, /in vivo/ experiments in awake
mice suggested that V1 cortical networks had a cut-off frequency above
this range (\(\sim\)100Hz in [[citetext:Reinhold2015]]).

This section concludes the comparison between numerical simulations of
network dynamics and the Markovian formalism. We showed that, despite
some discrepancies, this analytical framework describes both the
spontaneous activity and the response in the [0,100]Hz range of a
sparsely connected recurrent network of distinct excitatory and
inhibitory cells.

** Integrative properties of the network

#+ATTR_LATEX: :width .95\linewidth
#+NAME: fig:integrative-prop
#+CAPTION: *Integrative properties of the network model.* For all stimuli the waveform (Equation [[eq:input]]) keeps the temporal characteristics: \( \tau_1 \)=60ms and \( \tau_2 \)=100ms. For both *A* and *B*: (i) Time courses of the stimulus, the network response and the normalized membrane potential (see main text) (ii) Maximum of the population rate responses as a function of the amplitude. (iii) Maximum of the normalized membrane potential deflection as a function of the amplitude. *(A)* Stimulus-response relationship. We increase the amplitude of the stimulus from 0 to 15Hz. In (iii), we show the linear prediction (dashed line) for comparison. *(B)* Modulation of the response to a stimulus by various levels of background activity (external drive varied from 0 to 15Hz).
[[../figures/integrative_properties.png]]


As the computational cost of the analytical description is negligible,
we can now perform a detailed analysis of the network model. We want
to investigate the /integrative properties/ of the network, i.e. the
relation between the network response and the stimulus properties. We
analyzed two quantities in the network response: 1) the population
activity \(\nu(t) = (1-g) \nu_e(t) + g \nu_i(t) \), i.e. the firing
rates weighted by the fraction of neurons in each population, this is
the kind of signals sampled by multi-unit recordings, and 2) the
normalized membrane potential over the population \(\delta V(t)/V_0 =
(1-g) \, (V_m^{exc}(t)-V_{m,}^{stat})/V_{m}^{stat} + g
(V_m^{inh}(t)-V_{m,}^{stat})/V_{m}^{stat} \) where \( V_m^{exc}(t) \)
and \( V_m^{inh}(t) \) are the time courses of the excitatory and
inhibitory membrane potential respectively and \(V_{m}^{stat}\) is the
stationary membrane potenial value before stimulus onset. This
quantity provides a first approximation of the signal recorded by
voltage-sensitive dye imaging [[cite:Berger2007]], see [[citetext:Chemla2010]]
for a more detailed treatment of the relation between neural activity
and VSDi signals in a cortical column.

First, we investigated the relation between stimulus intensity and
network response, see [[fig:integrative-prop]]A. On top of the external
drive, we added a time-varying stimulus with various amplitudes, see
Figure [[fig:integrative-prop]]A(i). We found that the population activity
scaled linearly with the strength on the input. Therefore despite the
highly nonlinear dynamics of single neurons (see Figure [[fig:tf]]), the
network exhibits a linear response [[cite:VanVreeswijk1996]]. On the other
hand, the normalized membrane potential deflection (the "vsd-like
signal" in Figure [[fig:integrative-prop]]A(i,iii)) behave non linearly,
it exhibits a strong sublinear behavior (see the distance to the
linear prediction, dashed line in Figure
[[fig:integrative-prop]]A(iii)). This behavior follows from the non-linear
relation that associate the mean membrane potential to the excitatory
and inhibitory activities (Equation [[eq:mu-v]]): the mean membrane
potential is not a linear combination of the excitatory and inhibitory
contribution it is strongly /shunted/ by the total activity.

Another important /integrative property/ is how a given input will be
modulated by changes in local ongoing activity (that could either come
from local spontaneous fluctuations or from afferent activity). The
response in terms of population activity was found to be unaffected by
the level of background activity, again, in accordance with the
characteristics of a linear system. On the other hand the membrane
potential response exhibited a strong suppression (up to 60% of the
response in absence of additional drive). This phenomena also
naturally follows from the previously described non-linear
relationship between population activity and mean membrane potential.

** Embedding the model in a ring model to describe spatial integration

#+ATTR_LATEX: :width .8\linewidth
#+NAME: fig:ring
#+CAPTION: *A spatial model of the cortical sheet.* The balanced network units are embedded in a ring geometry. The lateral connectivity follows two Gaussian profile of extent \(l_{exc}\)=5mm and \(l_{inh}\)=1mm for the excitation and inhibition respectively.
[[../figures/ring.png]]

#+ATTR_LATEX: :float multicolumn :width \linewidth
#+NAME: fig:simple-stim
#+CAPTION: *Model response to a local stimulus.* An /early response line/ (see main text) indicates whether the signal exhibits propagation over space (vertical meaning no propagation), the line stops when the response is below 1% of the maximum signal over space. The yellow dotted line on the right of each plot represents to conduction velocity (300mm/s) for comparison. *(A)* Afferent stimulation: an input of the form Equation [[eq:ring-input]] with the parameters \(A\)=10Hz, \(\tau_1\)=50ms, \(\tau_2\)=150ms and \(l_{exc}\)=1.5mm. *(B)* Population response in terms of population firing rate (\(\sim\) multiunit signal). *(C)* Population response in terms of normalized membrane potential deflection  (\(\sim\) VSDi signal).
[[../figures/simple_stim.png]]

We now embed this local population dynamics description into a spatial
model to investigate the emergence of spatio-temporal integrative
properties.

The ring model (see e.g. [[cite:Hansel1996]]) offers a simple framework to
implement such interactions. The local balanced network units are
interconnected to each other via two Gaussian connectivity profiles
(see Figure [[fig:ring]] and Methods) according to anatomical connectivity
estimates [[cite:Buzas2006]]. Importantly, we integrate distance-dependent
propagation delays due to the finite velocity of axonal conduction of
action potentials (see Methods), we took here an axonal conduction
velocity of 300mm/s.

We stimulated this large-scale model with an external input mimicking
thalamic stimulation. We took a separable spatio-temporal waveform as
an input (see Equation [[eq:ring-input]]). In space, the profile was a
Gaussian curve, in time, it was a piecewise double Gaussian
function. Despite its various amplitude over space, it should be
emphasized that this input does not propagate: e.g. its maximum is
achieved at all position at the same time. To highlight this feature,
we implemented a simple analysis of propagation: we normalize the
responses with respect to their local amplitude and we look for a
specific crossing of the normalized amplitude. To focus on early
responses, we highlight the initial crossing of the fourth of the
normalized amplitude over space, we call it the /early response line/
(drawn with a white dashed-line, see Figure [[fig:simple-stim]]). In
Figure [[fig:simple-stim]]A, the horizontal /early response line/ indeed
show that the input does not propagate, the fourth of the maximum of
the normalized response is achieved everywhere at the same time.

The response of the model in terms of population dynamics showed a
marked propagation (see the V-shape of the /early response line/ in
Figure [[fig:simple-stim]]B). This is naturally the result of the local
connectivity profiles implemented in the model (see Figure [[fig:ring]]
and Table [[table:params]]), the excitation has a broad spatial extent, it
can depolarizes neighboring locations and evoke spiking (both of
excitatory and inhibitory populations). This propagated activity
nonetheless exhibits a very strong attenuation over space, this is due
to the strong non-linear relationship between depolarizations and
firing response (see previous sections). Confirming this picture, the
normalized membrane potential responses indeed exhibits the same
propagation profile but with a much weaker attenuation over
space. Naturally, the propagation dynamics in the model is led by the
conduction velocity, see its representation (yellow dotted line) in
Figure [[fig:simple-stim]]B,C. A strong prediction of the model is
therefore that the detectability of responses in multiunit recordings
have a lower spatial extent than for VSDi responses (see the lower
range of the /early response line/ that stops when the maximum local
response is below 1% of the maximum response).

The propagating wave in the model are thus very similar to those
detected in primary visual cortex of awake monkey, either in
spontaneous activity or following visual stimulation, as recently
shown by a phase-based analysis applied at single-trial level
[[cite:Muller2014]]. Note that, to highlight this qualitative similarity
between model and /in vivo/ VSDi recordings, the spatio-temporal
parameters of the input (\(\tau_1\)=50ms, \(\tau_2\)=150ms,
\(l_{exc}\)=1.5mm) have been manually calibrated to reproduce the
properties of the response observed as a response to a single Gaussian
blob in the visual space of \(0.5^o\) spatial extent.

** Deintricating the cortical operation underlying the response to an apparent motion stimulus

#+ATTR_LATEX: :float multicolumn :width \linewidth
#+NAME: fig:suppression
#+CAPTION: *Deintricating the cortical operation underlying the response to an apparent motion (AM) stimulus: comparison between the model and VSDi recordings in fixating monkeys.* *(A)* The apparent motion protocol. During a single trial, the monkey had to fixate on a central red dot for 12s. The animals gaze was constrained in a window of \(2^o \times 2^o\). Two Gaussian blob stimuli (each of \(0.5^o\) spatial extent) at two different position were successively presented during fixation. *(B)* VSDi allows for a real-time visualization of large neuronal population in primary visual cortex of fixating monkeys. *(C)* To deintricate the cortical computation, both in the theoretical model and in fixating monkey /in vivo/, we show the VSDi signal of different quantities: (i) the response to the first stimulus alone (ii) the response to the second stimulus alone, (iii) the linear prediction of the signal resulting from the two stimuli alone, (iv) the response to the two stimuli (AM stimulus) and (v) the spatio-temporal profile of the suppression signal (the linear prediction minus the observed response to the AM stimulation). The dashed magenta line in the model plot represents the conduction velocity. Note that the spatial scale in the model is higher than in the recordings (i.e. the model shows an enlarged region).
[[../figures/suppression.png]]


The presence of traveling waves detected in the VSDi signal in
response to simple stimuli [[cite:Muller2014]] raises the question of a
putative physiological role during the integration of complex
stimuli. Indeed, such transient depolarization of excitatory and
inhibitory neurons carried by the horizontal fiber network of the
superficial cortical layers might affect the processing of future
stimuli at distant points in visual cortex.

To investigate this possibility, a convenient paradigm is the apparent
motion protocol: two individual stimuli are successively flashed at
two neighboring visual locations (see Figure [[fig:suppression]]A). If the
interval between the two stimuli and the distances in visual space are
low enough, this give rise to the visual illusion of one moving object
instead of two different flashed objects, hence the name: /apparent
motion/ stimulus.

Using voltage-sensitive dye imaging in the primary visual cortex of
awake monkey (see Figure [[fig:suppression]]B), Chemla & Chavane
(unpublished observations) showed that two visual stimuli in different
positions in space and time evoke two distinct propagating waves,
which can collide, see Figure [[fig:suppression]]C(iv). To understand the
computation performed during this /collision/, they recorded the
response to the two simple stimuli alone, see Figure
[[fig:suppression]]C(i,ii), and then computed the linear prediction of the
expected spatio-temporal profile in the absence of cortical
operations, see Figure [[fig:suppression]]C(iii).

Notably, they found that the interaction between the two waves always
results in the propagation of a suppressive (sub-linear) wave at a
speed compatible with horizontal propagation (0.1-0.6 m/s). The
suppression affected the second stimulus first and then propagated
toward the first stimulus location.

We therefore tried to explain those observations in the light of our
theoretical model. As previously mentioned, we calibrated the
afferent input (mimicking thalamic input) to obtain a spatio-temporal
responses similar to those observed /in vivo/ (i.e. the cortical
distance between the two stimuli was estimated as 8.1mm for a 2^o
separation in the visual space). We next investigated the prediction
of the theoretical model in response to the apparent motion stimulus,
see Figure [[fig:suppression]]C.

Similarly to what was observed experimentally, we found that the
normalized membrane potential response ( \( \sim \) VSDi signal) to
the two successive inputs /collided/, see Figure [[fig:suppression]]C(iv),
and resulted in a strongly dampened signal with respect to the linear
prediction, see Figure [[fig:suppression]]C(v). This suppression signal
was also found to propagate from the second stimulus location toward
the first stimulus location. To investigate quantitatively the
properties of this propagation, we implemented the same /early
response line/ analysis than previously described (see previous
section). We found that the propagation of the suppression was led by
the conduction velocity (see comparison with the dotted magenta line
in Figure [[fig:suppression]]C(v)). Importantly, it should be noted that
in addition to this qualitative similarity, the quantitative
prediction of the model seems to match those of the experimental
recordings: the suppression peaks at \( \sim \) 50 \% of the response
to a single stimulus both in the model and in the VSDi recordings (for
the experimental recordings, response to first and second stimulus
have a maximum of \(\Delta F /F \sim 12 \) \textperthousand,
suppression peaks at \(\Delta F /F \sim 6 \) \textperthousand, in the
model, the "VSDi-like" signal response to first and second stimulus
have a maximum of \( \delta V /V_0 \sim\) 6\%, suppression peaks at
\(\delta V /V_0 \sim 3\)\%) .


We conclude that the the horizontal fiber network combined with the
strongly sublinear relation between membrane potential deflection and
activity in the local network (see Figure [[fig:integrative-prop]])
appears as a putative sufficient explanation for the observation found
in VSDi recordings during an apparent motion stimulus in fixating
monkeys.

* Discussion
\normalsize

The present study has two main contributions. 

In a first part, we investigated whether the Markovian formalism
proposed in [[citetext:ElBoustani2009]] is able to describe the temporal
dynamics of artificial neural networks. Though this formalism was
shown to be a relatively accurate description of the response
simulated in numerical networks, we highlighted two example phenomena
that were missed by our description. The relative complexity of the
theoretical problem should be stressed, indeed no exact treatment of
this situation could be achieved as this represents a really tough
mathematical problem.

In a second part, by taking advantage of this theoretical work
performed at the mesoscopic level (\(\sim\) 10000 neurons) to
analytically describe population dynamics in terms of few variables,
we were able to design a tractable model of population dynamics in
Layer II-III at the \(\sim\) 30 millimeter scale of the neocortical
sheet. We studied the properties of this model in the context of
multi-input integration. In particular, we implemented a typical
paradigm of visual processing: the apparent motion protocol. Similarly
to what is observed /in vivo/ we found a strong suppression signal
originating in the second stimulus that propagated toward the first
stimulus.

Unlike previous studies
[[cite:Brunel2000,Vogels2005,Kumar2008,ElBoustani2009]], we introduced
asymmetric electrophysiological properties between excitatory and
inhibitory cells. The reason was twofold: first it was an insightful
step to demonstrate the relative accuracy of the markovian formalism
(with the semi-analytical approach) in a situation including this
increased complexity, but more importantly, this asymmetry in the
excitabilities was the mechanism that led to a very strong suppression
in the response to multiple inputs.  When the external stimulation
increases the local excitatory activity, inhibition is recruited via
recurrent connections and because of its higher excitability this
recruitment is stronger than for the excitatory population (see
e.g. Figure [[fig:mf-temp-pred]]B).This feature, combined with the
interplay of driving forces, produced an inhibitory control of the mean
membrane potential fluctuations.

Other suppressive mechanisms were present in this model: conductance
shunting of the external input due to background activity
[[cite:Ho2000,Chance2002]] (where an increase in background activity is
evoked by the first stimulus) as well spike-frequency adaptation
currents (as least its stationary effect). The effect of those
mechanisms has been investigated in absence of the
electrophysiological asymmetry (i.e. by considering pure FS cells
networks and pure RS cell network), they indeed produced a suppression
with a similar spatio-temporal pattern such as the one observed in the
experimental data. Nonetheless, when keeping their value to estimated
physiological range, the amplitude of the suppression was at least one
order of magnitude lower than that observed in experimental recordings
(not shown, but the slight suppression for the firing activity in
Figure [[fig:integrative-prop]]B(ii) is the trace of this effect), thus
suggesting that they weakly participate to the very strong suppression
effect observed in VSDi recordings.

An important remark is that the strong suppressive mechanism had to be
cortico-cortical to account for the experimental
observations. Depression at the thalamo-cortical synapses can
contribute to the suppression of cortical responses (see
[[citetext:Carandini2002]] for cross-orientation suppression), but this
seems unlikely to play here as the sensory stimuli are well separated
in the visual space and are likely to also be well separated in the
thalamus, thus ruling out the hypothesis of synaptic
depression at the thalamo-cortical synapse.

We envision several future directions for the present model.

First, the theoretical descriptions of the local cortical network
could be improved. For example the strong hyperpolarization of
population activity after a transient rise (see Figure
[[fig:mf-temp-pred]]B) was shown to be missed by the formalism under this
version. Indeed, this version does not have a memory of the previous
activity levels and thus can not account for the effect of the
long-lasting spike-frequency adaptation mechanism that has been
strongly activated by the activity evoked by the stimulus. This is
easily solvable within the Markovian framework, one can introduce a
new variable: the "population adaptation current", that can directly
be derived from the equation of the AdExp model (not shown).  The
simplicity and high tractability of this model in its current form
would allow several inclusion without running into the drawback of a
high computational cost.

Finally, we would like to test the model ability to explain other
typical cortical properties. In particular, similar propagation of
suppressive interactions have already been shown but using bipartite
stationary stimuli [[cite:Reynaud2012]], unveiling the cortical dynamics
subtending the so-called surround suppression. What is the explanatory
power of the model in the surround suppression framework ? As an
additional example, the response to a stimulus depends on the level of
ongoing activity [[cite:Arieli1996]] dependency on the level of ongoing
activity. When the the ongoing activity is modulated by the level of
afferent activity is this model sufficient to describe the
spatio-temporal variability in evoked response ? Answering those
questions will be the focus of future work.

* References 
\small

\bibliography{biblio}



