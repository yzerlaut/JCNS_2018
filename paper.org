#+TITLE: A markovian model for spatio-temporal population dynamics in neocortex
#+AUTHOR:  Collab.: S. Chemla^1 & F. Chavane^1 (/in vivo/ VSD imaging)
#+DATE:  \textsc{Y. Zerlaut}^2 & \textsc{A. Destexhe}^2 
#+INCLUDE: my_template.org

* Key points summary :noexport:
\bfseries

- We investigate whether the markovian formalism proposed in
  [[citetext:ElBoustani2009]] allows to describe the population dynamics
  of a network of excitatory and inhibitory neurons with different
  electrophysiological properties.

- Comparison with numerical simulations.

- Investigating the integrative properties of the mean field model.

- Implementation in a ring geometry to describe the spatial
  integration across the neocortical sheet.

- Comparison with optical imaging of spatio-temporal dynamics in the
  primary visual cortex of awake behaving monkey (Chemla & Chavane,
  unpublished results).

\normalfont

* Abstract
\bfseries

The focus of the present communication is to design a theoretical
model of neocortical dynamics with the following properties: 1) it
operates at the temporal and spatial scales scanned by optical imaging
and 2) it has a correlate in terms of single-cell dynamics (in
particular membrane potential dynamics), so that the model can
directly generate predictions for the signal imaged by the
voltage-sensitive dye imaging technique.

In this communication, by comparing its prediction with numerical
simulations of artificial neural networks, we investigate whether the
markovian formalism proposed in [[citetext:ElBoustani2009]] allows to
describe the population dynamics of a network of excitatory and
inhibitory neurons with different electrophysiological properties. In
particular, we investigate whether this formalism generalizes to the
description of network dynamics in the presence of time-dependent
inputs. We find that, while missing a resonant behavior at
\(\sim\)70Hz, the response to slow modulations (0-40Hz) provides a
good approximation of the response of this complex numerical neural
networks. We next analyze the integrative properties of the model: how
does it responds to increasing stimuli strength or how is it modulated
by an increase in external background activity. We found that, while
the firing response scales linearly the response in terms of membrane
potential variations over the population exhibits a strong
suppression. We then embed this local network description
(\(\sim\)10000 neurons) in a ring geometry to describe the spatial
integration across the neocortical sheet. We re-construct a typical
experimental paradigm of visual processing: the apparent-motion
protocol and we compare the model's response to optical imaging of
spatio-temporal dynamics in the primary visual cortex of awake
behaving monkey (Chemla & Chavane, unpublished results). We found a
similar strong suppression as observed /in vivo/, our study therefore
proposes a precise mechanistic understanding of this phenomena.

\normalfont

* Introduction 
\normalfont

Recent advances in imaging technique, in particular voltage-sensitive
dye imaging (VSDi), have revealed fundamental properties of
neocortical processing
[[cite:Arieli1996,Contreras2001,Petersen2001,Ferezou2006,Civillico2012]]:
subthreshold responses to sensory inputs are locally homogeneous in
primary sensory areas, depolarizations tend to spread across spatially
neighboring regions and responses to sensory stimuli are strongly
affected by the level of ongoing activity. It also appears as great
tools to undesrtand how the spatio-temporal dynamics in the neocortex
shape canonical cortical operations such as normalization
[[cite:Reynaud2012]].


On the other hand, the litterature lacks, to our knowledge, a
theoretical model that provides a detailed account of those phenomena
with a clear relation between how this signal is generated and those
physiolgical principles at that spatial scale (i.e. at the millimeters
or centimeters scale).

The aim of the present communication is to design a theoretical model
of neocortical dynamics with the following properties: 1) it should
operate at the temporal and spatial scales of optical imaging and 2)
it has a correlate in terms of single-cell dynamics (in particular
membrane potential dynamics), so that the model can directly generate
predictions for the signal imaged by the VSDi technique
[[cite:Berger2007]].

More specifically, our study focuses on network dynamics in
/activated/ cortical states, thus the desired model should describe
neocortical computation in the asynchronous regime, where cortical
activity is characterized by irregular firing and strong subthreshold
fluctuations at the neuronal level [[cite:Steriade2001,Destexhe2003]]. The
strategy behind the present model is to take advantage of the
/mean-field/ descriptions of network dynamics in this regime. Via
self-consistent approaches, those descriptions allow to capture the
dynamical properties of population activity in recurrent networks
[[cite:Amit1997,Brunel1999,Brunel2000,Latham2000,ElBoustani2009]]. The
model thus relies on the following scheme: 1) we consider the randomly
connected network of 10000 neurons as a unit to describe a cortical
column and 2) we embeded the analytical description of this cortical
column model into a ring geometry with physiological local
connectivity profiles to model spatio-temporal integration on the
neocortical sheet.

A prerequisite was therefore to establish the accuracy of the
analytical description of the cortical column model. This is the focus
of the first part of this paper: by comparing analytical prediction of
the model with numerical simulations, we can precisely evaluate the
accuracy and/or weaknesses of the analytical description to evaluate
its potential impact on the modeling of the network.

The second part of the paper investigates the properties of the model

* Material and Methods
\small

We describe the equations and parameters used for the neuronal,
synaptic and network modeling. We present our /heuristic/ treatment of
the neuronal /transfer functions/: the quantity that accounts for the
cellular computation in /mean-field/ models of population
activity. Then, we present the specific markovian model of population
activity used in this study. Finally, we embed this description of
local population dynamics in a ring model to describe spatio-temporal
integration on the neocortical sheet.

** Single neuron models

The neuronal model used in this study is the adaptative exponential
and fire (AdExp) model [[cite:Brette2005a]]. The equation for the membrane
potential and the adaptation current therefore reads:

#+NAME: eq:iAdExp
\begin{equation}
\hspace{-.2cm}
  \left\{
  \begin{split}
  & C_\mathrm{m}\,\frac{dV}{dt} = g_\mathrm{L} \,(E_\mathrm{L}-V) + I_{syn}(V,t) + k_a e^{\frac{V - V_{thre} }{k_a}}- I_w \\
  & \tau_w \frac{d I_w}{dt} = - I_w + \sum_{t_s \in \{t_{spike}\}} b \, \, \delta (t-t_s)
  \end{split}
\right.
\end{equation}

where $I_{syn}(V, t)$ is the current emulating synaptic activity that
will create the fluctuations, $I_w$ reproduces the I_m current
[[cite:McCormick1985]]. The spiking mechanism is the following: when
$V(t)$ reaches \(V_{thre}+5 \, k_a \), this triggers a spike t_s \in
\{t_{spike}\}, this increases the adaptation variable $I_w$ by \(b\),
the membrane potential is then clamped at \(E_L\) for a duration
\tau_{refrac}=5ms. We consider two versions of this model: a regular
spkiking neuron for the excitatory cells and a fast spiking neuron for
the inhibitory cells (see Figure [[fig:tf]]). The parameters of those two
models can be found on Table [[table:params]].

#+ATTR_LATEX: :float multicolumn
#+NAME: table:params
#+CAPTION: *Model parameters*. The passive properties and the mean morphology are fitted while 
| *Parameters*          | Parameter Name                 | Symbol            | Value | Unit |
|-----------------------+--------------------------------+-------------------+-------+------|
| /                     | <>                             | <>                |    <> | /    |
|                       |                                |                   |       |      |
| *cellular properties* |                                |                   |       |      |
|                       | leak conductance               | \(g_L\)           |    10 | nS   |
|                       | leak reversal potential        | \(E_L\)           |   -65 | mV   |
|                       | membrane capacitance           | \(C_m\)           |   150 | pF   |
|                       | leak reversal potential        | \(E_L\)           |   -65 | mV   |
|                       | AP threshold                   | \(V_{thre}\)      |   -50 | mV   |
|                       | refractory period              | \(\tau_{refrec}\) |     5 | ms   |
|                       | adaptation time constant       | \(\tau_w\)        |   500 | ms   |
| *excitatory cell*     |                                |                   |       |      |
|                       | sodium sharpness               | \(k_a\)           |     2 | mV   |
|                       | adaptation current increment   | \(b\)             |    20 | pA   |
|                       | adaptation conductance         | \(a\)             |     4 | nS   |
| *inhibitory cell*     |                                |                   |       |      |
|                       | sodium sharpness               | \(k_a\)           |   0.5 | mV   |
|                       | adaptation current increment   | \(b\)             |     0 | pA   |
|                       | adaptation conductance         | \(a\)             |     0 | nS   |
| *synaptic properties* |                                |                   |       |      |
|                       | excitatory reversal potential  | \(E_e\)           |     0 | mV   |
|                       | inhibitory reversal potential  | \(E_i\)           |   -80 | mV   |
|                       | excitatory quantal conductance | \(Q_e\)           |     1 | nS   |
|                       | inhibitory quantal conductance | \(Q_i\)           |     5 | nS   |
|                       | excitatory decay               | \(\tau_e\)        |     5 | ms   |
|                       | inhibitory  decay              | \(\tau_i\)        |     5 | ms   |
| *numerical network*   |                                |                   |       |      |
|                       | cell number                    | \(N_{tot}\)       | 10000 |      |
|                       | connectivity probability       | \(\epsilon\)      |    5% |      |
|                       | fraction of inhibitory cells   | g                 |   20% |      |
|                       | external drive                 | \(\nu_e^{drive}\) |     4 | Hz   |
| *ring model*          |                                |                   |       |      |
|                       | total extent                   | \(L_{tot}\)       |    40 | mm   |
|                       | excitatory connectivity extent | \(l_{exc}\)       |     5 | mm   |
|                       | inhibitory connectivity extent | \(l_{inh}\)       |     1 | mm   |
|                       | propagation delay              | \(v_c\)           |   300 | mm/s |

** Synaptic model

The time- and voltage-dependent current that stimulate the neuron is
made of the sum of an excitatory and inhibitory currents (indexed by
\(s \in \{e,i\}\) and having a reversal potential \(E_s\)):

#+NAME: eq:syn-current
\begin{equation}
 I_{syn}(V,t) = \sum_{s \in \{e,i\}} \sum_{t_s \in \{t_s\}} Q_s \, e^{-\frac{t}{\tau_s}} \, (E_{s}-V) \, \mathcal{H}(t-t_s)
\end{equation}
where \(\mathcal{H}\) is the Heaviside function.

This synaptic model is refered to as the /conductance-based
exponential/ synapse. The set of events \(\{t_e\}\) and \(\{t_i\}\)
are the set of excitatory and inhibitory events arriving to the
neuron. In numerical simulations of single neurons, it will be
generated by stationary Poisson processes. In numerical simulations of
network dynamics it will correspond to the set of spike times of the
neurons connecting to the targent neurons, both via recurrent and
feedforward connectivity.

** Numerical network model

#+ATTR_LATEX: :width .6\linewidth
#+NAME: ntwk-architect
#+CAPTION: *Schematic of the local network architecture*. The network is made of \(N_e=(1-g) \, N_{tot}\) excitatory and \(N_i=g \, N_{tot}\) inhibitory neurons. All excitatory connections (afferent and recurrent) onto a neuron corresponds to \(K_e= \epsilon \, (1-g) \, N_{tot}\) synapses of weight \(Q_e\). All inhibitory connections (afferent and recurrent) onto a neuron corresponds to \(K_i= \epsilon \, g \, N_{tot}\) synapses of weight \(Q_i\)
[[../figures/architext-ntwk.png]]

All simulations of numerical network were performed with the =brian2=
simulator [[cite:Goodman2009]], see [[http://brian2.readthedocs.org]]. For all
simulations, the network was composed of \(N_{tot}\)=10000 neurons,
separated in two populations, one excitatory and one inhibitory with a
ratio of g=20% inhibitory cells. Those two populations we recurrently
connected (internally and mutually) with a connectivity probability
\(\epsilon\)=5%.

Because this network did not display self-sustained activity (see
Figure [[fig:phase-space]], in contrast to [[citetext:Vogels2005]]), an
excitatory population exerted an /external drive/ to bring the network
out of the quiescent state. This population targetted both the
excitatory and inhibitory neurons. Note that the firing rate of this
population was linearly increased to avoid a too strong initial
synchronization (see Figure [[fig:ntwk-act]]). Finally, an excitatory
population of time varying firing rate could was added to evoke
activity transients in the population dynamics. This last stimulation
targetted only the excitatory population. The number of neurons in
those two excitatory populations was taken as identical to the number
of excitatory neurons (i.e. \((1-g)\,N_{tot}\)) and created synapses
onto the recurrent network with the same probability
\(\epsilon\). After temporal discretization, the firing rates of those
afferent populations were converted into spikes by using the
properties of a Poisson process (i.e. eliciting a spike at \(t\) with
a probability \(\nu(t) \,dt \)). All simulations were performed with a
time-step dt=0.1ms.

** Estimating the transfer functions of single neurons

The transfer function \(\mathcal{F}\) of a single neuron is defined
here as the function that maps the value of the stationary excitatory
and inhibitory presynaptic release frequencies to the output
stationary firing rate response, i.e. \(\nu_{out} = \mathcal{F}(\nu_e,
\nu_i)\). Note the stationary hypothesis in the definition of the
transfer function (see discussion in main text).

Because an analytical solution of this function for the single neuron
models considered in our study is a very challenging mathematical
problem, we adopted a semi-analytical approach. We performed numerical
simulations of single cell dynamics at various excitatory and
inhibitory presynaptic frequencies (\(\nu_e\) and \(\nu_i\)
respectively) (see the output in Figure [[fig:tf]]) on which we fitted the
coefficients of an analytical template to capture the single cell
model's response.

The procedure relied on fitting a /phenomenological threshold/
\(V_{thre}^{eff}\) that accounts for the single neuron non-linearities
(spiking and reset mechanism, adaptation mechanisms) on top of the
subthreshold integration effects [[cite:Zerlaut2016]]. This
phenomenological threshold is then plugged-in into the following
formula (analogous to [[citetext:Amit1997]]) to become our firing response
estimate:

#+NAME: eq:template
\begin{equation}
  \nu_{out} = \frac{1}{2\,\tau_V} \cdot 
  {Erfc}(\frac{V_{thre}^{eff}-\mu_V}{\sqrt{2} \, \sigma_V})
\end{equation}

Where \( (\mu_V, \sigma_V, \tau_V) \) are the mean, standard deviation
and autocorrelation time constant of the membrane potential
fluctuations. How to calculate those quantities as a response to a
stationary stimulation is the focus of the next section.

The phenomenological threshold was taken as a second order polynomial
in the three dimensional space \( (\mu_V, \sigma_V, \tau_V) \):

#+NAME: eq:quadratic-threshold
\begin{equation}
  \begin{split}
   V_{thre}^{eff} & (\mu_V, \sigma_V, \tau_V^N) = P_0 + 
   \sum_{x \in \{ \mu_V, \sigma_V, \tau_V^N\}} P_x \cdot \Big(  \frac{x - x^0}{\delta x^0} \Big) + \\
   & \sum_{ x,y \in \{ \mu_V, \sigma_V, \tau_V^N\}^2} P_{xy} \cdot
   \Big( \frac{x - x^0}{\delta x^0}  \Big) \,  \Big( \frac{y - y^0}{\delta y^0} \Big)
 \end{split}
\end{equation}

Where the normalization factors \(\mu_V^0\)=-60mV, \(\delta
\mu_V^0\)=10mV, \(\sigma_V^0\)=4mV, \(\delta \sigma_V^0\) = 6mV,
\(\tau_V^{N0}\)=0.5 and \(\delta \tau_V^{N0}\)= 1 arbitrarily delimits
the /fluctuation-driven/ regime (a mean value $x$ and an extent
$\delta x$, \(\forall x \in \{\mu_V, \sigma_V, \tau_V^N\}\)).  They
render the fitting of the phenomenological threshold easier, as they
insure that the coefficients take similar values. It is kept constant
all along the study. The phenomenological threshold was taken as a
second order polynomial and not as a linear threshold, for two
reasons: 1) unlike in an experimental study [[cite:Zerlaut2016]], we are
not limited by the number of sampling points, the number of fitted
coefficients can thus be higher as the probability of overfitting
becomes negligible 2) it gives more flexibility to the template,
indeed the linear threshold was found a good approximation in the
/fluctuation-driven/ regime, i.e. when the diffusion approximation
holds, however, for low values of the presynaptic frequencies, we can
be far from this approximation, the additional coefficients are used
to capture the firing response in those domains.


The fitting procedure was identical to [[citetext:Zerlaut2016]], it
consisted first in a linear regression in the phenomenological
threshold space of Equation [[eq:quadratic-threshold]], followed by a
non-linear optimization of Equation [[eq:template]] on the firing rate
response. Both fitting were performed with the =leastsq= method in the
=optimize= package of =SciPy=.

** Calculus of the subthreshold membrane potential fluctuations

Here, we detail the analytical calculus that translate the input to
the neuron into the properties of the membrane potential
fluctuations. The input is made of two Poisson shotnoise: one
excitatory and one inhibitory that are both convoluted with an
exponential waveform to produce the synaptic conductances time
courses.

*** Conductances fluctuations

From Campbell's theorem [[cite:Papoulis1991]], we first get the mean
(\(\mu_{Ge}, \mu_{Gi}\)) and standard deviation (\(\sigma_{Ge},
\sigma_{Gi}\)) of the excitatory and inhibitory conductance
fluctuations:

\begin{equation}
\begin{split}
& \mu_{Ge}(\nu_e, \nu_i) = \nu_e \, K_e \, \tau_e \, Q_e \\
& \sigma_{Ge}(\nu_e, \nu_i) = \sqrt{\frac{\nu_e \, K_e \, \tau_e}{2}} \, Q_e \\
& \mu_{Gi}(\nu_e, \nu_i) = \nu_i \, K_i \, \tau_i \, Q_i \\
& \sigma_{Gi}(\nu_e, \nu_i) = \sqrt{\frac{\nu_i \, K_i \, \tau_i}{2}} \, Q_i 
\end{split}
\end{equation}

The mean conductances will control the input conductance of the neuron
\(\mu_G\) and therefore its effective membrane time constant
\(\tau_m\):

\begin{equation}
\begin{split}
& \mu_{G}(\nu_e, \nu_i) = \mu_{Ge} + \mu_{Gi} + g_L \\
& \tau_m(\nu_e, \nu_i) = \frac{C_m}{\mu_{G}}\\
\end{split}
\end{equation}

*** Mean membrane potential

Following [[citetext:Kuhn2004]], the mean membrane potential is obtained
by taking the stationary solution to static conductances given by the
mean synaptic bombardement (for the passive version of Equation
[[eq:iAdExp]], i.e. removing the adaptation and spiking mechanisms). We
obtain:

#+NAME: eq:mu-v
\begin{equation}
\mu_V(\nu_e, \nu_i) = \frac{\mu_{Ge} \, E_e + \mu_{Gi} \, E_i + g_L \, E_L}{\mu_{G}}
\end{equation}

We will now approximate the driving force \(E_s - V(t)\) of synaptic
events by the level resulting from the mean conductance bombardment:
\(E_s - \mu_V\). This will enable an analytical solution for the
standard deviation \( \sigma_V\) and the autocorrelation time \(
\sigma_V\) of the fluctuations/

*** Power spectrum of the membrane potential fluctuations

Obtaining \( \sigma_V\) and \(\tau_V\) is achieved by computing the
power spectrum density of the fluctuations. In the case of Poisson
processes, the power spectrum density of the fluctuations resulting
from the sum of events \(PSP_{s}(t)\) at frequency \(K_{s} \, \nu_s\)
can be obtained from shotnoise theory [[cite:Daley2007]]:

\begin{equation}
\begin{split}
 P_V(f)  = & \sum_{s \in \{e,i\}} K_s \, \nu_{s} \, \| \hat{\mathrm{PSP}_s}(f) \|^2
\end{split}
\end{equation}

where \(\hat{\mathrm{PSP}_s}(f)\) is the Fourier transform of the
time-varying function \(\mathrm{PSP}(t)\). Note that the relations
presented in this paper rely on the following convention for the
Fourier transform: \( \hat{F}(f) = \int_\mathbb{R} F(t) \, e^{- 2 i
\pi f t} \, dt\).

After fixing the driving force to \(E_s - \mu_V\), the equation for a
 post-synaptic membrane potential event \(s\) around \(\mu_V\) is

\begin{equation}
 \tau_m \frac{d \, \mathrm{PSP}_s }{dt} + \mathrm{PSP}_s = U_s \, \mathcal{H}(t) \, e^{\frac{-t}{\tau_s}}
\end{split}
\right.
\end{equation}

where \( U_s = \frac{Q_s}{\mu_G} (E_s - \mu_V) \) and \(
\mathcal{H}(t) \) is the Heaviside function.

Its solution is:

\begin{equation}
\mathrm{PSP}_s(t)  = U_s \, \frac{\tau_s}{\tau_m - \tau_s} \, \big( 
e^{\frac{-t}{\tau_m}} - e^{\frac{-t}{\tau_s}} \big) \, \mathcal{H}(t)
\end{equation}

We take the fourier transform:

\begin{equation}
\hat{\mathrm{PSP}_s}(f) = U_s \, \frac{\tau_s}{\tau_m - \tau_s} \, 
\big(
\frac{\tau_{m}}{2 \, i  \,  \pi \, f \, \tau_{m} +1} 
- \frac{\tau_s}{2 \, i  \,  \pi \, f \, \tau_s +1} \big)
\end{equation}

We will need the value of the square modulus at \(f=0\):

#+NAME: eq:psp0
\begin{equation}
\| \hat{\mathrm{PSP}}(0) \|^2 = (U_s \cdot \tau_s)^2
\end{equation}

As well as the integral of the square modulus:

#+NAME: eq:psp-int
\begin{equation}
\int_\mathbb{R}  df \, \| \hat{\mathrm{PSP}}(f) \|^2 = \frac{(U_s \cdot \tau_s)^2}{2 \, (\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) }
\end{equation}

*** Standard deviation of the fluctuations

The standard deviation follows:

\begin{equation}
 (\sigma_V)^2  = \int_\mathbb{R}  df \, P_V(f)
\end{equation}

Using Equation [[eq:psp-int]], we find the final expression for \(\sigma_V\):

#+NAME: eq:sigma-v
\begin{equation}
 \sigma_V(\nu_e, \nu_i)  = \sqrt{ \sum_s K_s \, \nu_s \, \frac{(U_s \cdot \tau_s)^2}{2 \, (\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) } }
\end{equation}

*** Autocorrelation-time of the fluctuations

We defined the global autocorrelation time as [[cite:Zerlaut2016]]:

\begin{equation}
  \tau_V = \frac{1}{2} \, \big( \frac{\int_\mathbb{R} P_V(f) \, d f}{ P_V(0) } \big)^{-1}
\end{equation}

Using Equations [[eq:psp-int]] and [[eq:psp0]], we find the final expression
for \(\tau_V\):

#+NAME: eq:tau-v
\begin{equation}
  \tau_V(\nu_e, \nu_i) = \Big( \frac{
  \sum_s \big( K_s \, \nu_s \, (U_s \cdot \tau_s)^2\big) 
  }{
  \sum_s \big( K_s \, \nu_s \, (U_s \cdot \tau_s)^2 /(\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) \big)
  } \Big)
\end{equation}

Therefore the set of Equations [[eq:mu-v]], [[eq:sigma-v]] and [[eq:tau-v]]
translate the presynaptic frequencies into membrane fluctuations
properties \(\mu_V, \sigma_V, \tau_V\).

The previous methodological section allowed to translate the
fluctuations properties \(\mu_V, \sigma_V, \tau_V\) into a spiking
probability thanks to a minimization procedure. The combination of the
present analytical calculus and the previous fitting procedure (on
numerical simulations data) constitute our semi-analytical approach to
determine the transfer function of a single cell model: \( \nu_{out} =
\mathcal{F}(\nu_e, \nu_i)\).

** Master equation for local population dynamics

An analytical description of the cellular transfer function is the
core of theoretical descriptions of asynchronous dynamics in sparsely
connected random networks [[cite:Amit1997,Brunel2000,Renart2004]].

Because we will investigate relatively slow dynamics
(\(\tau\)>25-50ms) (and because of the stationary formulation of our
transfer function), we will use the Markovian description develloped
in [[citetext:ElBoustani2009]], it describes network activity at a time
scale \(T\), for which the network dynamics should be Markovian. The
choice of the time-scale \(T\) is quite crucial in this formalism, it
should be large enough so that activity can be considered as
memoryless (e.g. it can not be much smaller than the refractory
period, that would introduce memory effects) and small enough so that
each neuron can fire statistically only once per time interval
\(T\). Following [[citetext:ElBoustani2009]], we will arbitrarily take
\(T\)=5ms all along the study as it offers a good compromise between
those two constraints. 


The formalism describes the first and second moments of the population
activity for each populations. We consider here two populations: one
excitatory and one inhibitory, the formalism thus describes the
evolution of five quantities: the two means \(\nu_e(t)\) and
\(\nu_i(t)\) of the excitatory and inhibitory population activity
respectively (the instantaneous population firing rate, i.e. after
binning in bins of \(T\)=5ms, see discussion in
[[citetext:ElBoustani2009]]), the two variances \(c_{ee}(t)\) and
\(c_{ii}(t)\) of the the excitatory and inhibitory population activity
respectively and the covariance \(c_{ei}(t)\) between the excitatory
and inhibitory population activities. The set of differential
equations followed by those quantities reads [[cite:ElBoustani2009]]:

#+NAME: eq:master-equation
\begin{equation}
\left\{
\begin{split}
T \, \frac{\partial \nu_\mu}{\partial t} = & (\mathcal{F}_\mu - \nu_\mu )
   + \frac{1}{2} \, c_{\lambda \eta} \, 
\frac{\partial^2 \mathcal{F}_\mu}{\partial \nu_\lambda \partial \nu_\eta} \\
T \, \frac{\partial c_{\lambda \eta} }{\partial t}  =  & A_{\lambda \eta} +
(\mathcal{F}_\lambda - \nu_\lambda ) \, (\mathcal{F}_\eta - \nu_\eta ) + \\
 & c_{\lambda \mu} \frac{\partial \mathcal{F}_\mu}{\partial \nu_\lambda} +
 c_{\mu \eta} \frac{\partial \mathcal{F}_\mu}{\partial \nu_\eta} 
 - 2  c_{\lambda \eta}
\end{split}
\right.
\end{equation}

with:
\begin{equation}
A_{\lambda \eta} =  
\left\{
\begin{split}
\frac{\mathcal{F}_\lambda \, (1/T - \mathcal{F}_\lambda)}{N_\lambda} 
\qquad & \textrm{if  } \lambda=\eta \\
0 \qquad & \textrm{otherwise}
\end{split}
\right.
\end{equation}

Note that, for the concision of the expressions, we used Einstein's
index summation convention: if an index is repeated in a product, a
summation over the whole range of value is implied (e.g. we sum over
\(\lambda \in \{e,i\} \) in the first equation, note that,
consequently, \(\lambda\) does not appear in the left side of the
equation). Also the dependency of the firing rate response to the
excitatory and inhibitory activities has been omitted: yielding
\(\mathcal{F}_\mu\) instead of \(\mathcal{F}_\mu(\nu_e,\nu_i)\),
\(\forall \mu \in \{e,i\} \).

We will also use the reduction to first order of this system (for the
phase-space analysis, see Results). This yields:

#+NAME: eq:master-eq-1st-order
\begin{equation}
T \, \frac{\partial \nu_\mu}{\partial t} = \mathcal{F}_\mu - \nu_\mu \\
\end{equation}

** Ring model 

We now embed the previous markovian description of population dynamics
in a ring geometry to model spatio-temporal integration on the
neocortical sheet. For simplicity, we consider here only the first
moments of the second-order description: i.e. the means of the
excitatory and inhibitory population activities: \(\nu_e(t)\) and
\(\nu_i(t)\) respectively. 

We introduce the gaussian connectivity profiles (see Figure
[[fig:simple-stim]]) that defines the connectivity across cortical columns
(i.e. local networks described in the previous section):

\begin{equation}
\mathcal{N}_e(x) = \frac{1}{\sqrt{2 \pi} l_e} e^{-(\frac{x}{\sqrt{2} l_e})^2} \quad ; \quad 
\mathcal{N}_i(x) = \frac{1}{\sqrt{2 \pi} l_i} e^{-(\frac{x}{\sqrt{2} l_i})^2}
\end{equation}

where \(l_e\) and \(l_i\) are the excitatory and inhibitory extent of
the connectivity profiles respectively.

We also introduce the effect of a finite axonal conduction speed
\(v_c\), this will intriduce delays for the propagation of activity
across cortical columns: for a network at a distance \(x\), the
afferent activity will arrive delayed by \(x/v_c\).

Finally, the equations that govern the activity in space and time are
given by:

\begin{equation}
\left\{
\begin{split}
\nu_e^{input}(x,t) = &\nu_e^{drive}  + 
\int_\mathbb{R} dy \, \mathcal{N}_e(x-y) \, \nu_e(y, t-\|y-x\|/v_c) \\
\nu_i^{input}(x,t) = & \int_\mathbb{R} dy \, \mathcal{N}_i(x-y) \, \nu_i(y, t-\|y-x\|/v_c) \\
T \frac{\partial \nu_e(x,t)}{\partial t} = & -  \nu_e(x,t) + \\
& \mathcal{F}_e(\nu_e^{aff}(x,t)+\nu_e^{input}(x,t), \nu_i^{input}(x,t) ) \\
T \frac{\partial \nu_i(x,t)}{\partial t} = & -  \nu_i(x,t) + \mathcal{F}_i(\nu_e^{input}(x,t), \nu_i^{input}(x,t) )
\end{split}
\right.
\end{equation}

where \(\nu_e^{drive}\) is the external drive and \(\nu_e^{aff}(x,t)\)
is the afferent (thalamic) stimulation.

The local correlate in terms of mean membrane potential \(\mu_V(x,t)\)
is given by Equation [[eq:mu-v]].

** Afferent stimulation 

The afferent input was choosen as a piecewise double gaussian waveform:

#+NAME: eq:input
\begin{equation}
\nu_e^{aff}(t) = A \, \Big(
e^{-(\frac{t-t_0}{\sqrt{2} \tau_1})^2} \mathcal{H}(t_0-t)+
e^{-(\frac{t-t_0}{\sqrt{2} \tau_2})^2} \mathcal{H}(t-t_0)
\Big)
\end{equation}

Thus, we independently control: 1) the maximum amplitude \(A\) of the
stimulation, its rising time constant \(\tau_1\) and its decay time
constant \(\tau_2\).

* Results
\normalsize

The results are organized as follows. We first construct the
analytical model that will describe the dynamics of a single cortical
column. In particular, we describe the semi-analytical workflow that
enables the derivation of the cellular transfer function: the core of
the population model. Next, we investigate whether the analytical
description accurately descrive population dynamics by comparing its
prediction to numerical simulations. Thenm we investigate the
integrative properties of the network model. Finally we embed the
cortical column model into a ring model and we compare its predictions
to VSDi recordings in the visual cortex of awake behaving monkey.

** Modeling a single cortical column

#+ATTR_LATEX: :float multicolumn :width .7\linewidth
#+NAME: fig:tf
#+CAPTION: *Single cell models of the excitatory and inhibitory populations.* Top: response to a current step of 200pA lasting 300ms. Bottom: /transfer function/ of the single cell, i.e. output firing rate as a function of the excitatory (x-axis) and inhibitory (color-coded) presynaptic release frequencies. Note that the range of the excitatory and frequencies assumes numbers of synapses (\(K_e\)=40 and \(K_i\)=10 for the excitation and inhibition respectively).  *(A)* Excitatory cells. Note the presence of spike-frequency adaptation and subthreshold adaptation. *(B)* Inhibitory cells. Note the very narrow spike initiation dynamics (\(k_a\)=0.5mV). Also, note the steepest relation to excitation (with respect to the excitatory cell) at various inhibitory levels as a result of the increased exctability as a result of the increased excitaability of the inhibitory cell (with respect to the excitatory cell).
[[../figures/tf.png]]



Because optical imaging presumably sample most of its signals from
superficial layers, we model here the layer II/III network: it is
characterized by a strong recurrent connectivity and an important
cellular diversity, in particular one finds many types of interneurons
[[cite:Markram2004,Ascoli2008a]]. We adopt here a very simplistic
description of this network, it is made of two neuronal population:
one excitatory and one inhibitory comprising 8000 and 2000 neurons
respectively. All neurons within the two population synaptically
interconnect randomly to each other with a connectivity probability of
5%. The excitatory and inhibitory cells have the same passive
properties. We nonetheless include an assymetry between the excitatory
and inhibitory populations: because the inhibitory population includes
Fast-Spiking cells that can exhibit very high firing frequencies
[[cite:Markram2004]], we set its spiking mechanism sharper (more precisely
its sodium activation activation curve is steeper, see Methods) than
that of excitatory cells, additionally we add a strong spike-frequency
adaptation current in excitatory cells that is absent in inhibitory
cells. Those two effects render the inhibitory neurons more excitable
(see the different responses to the same current step in Figure
[[fig:tf]]). All parameters of the cortical column can be found in Table
[[table:params]].

** A Markovian model to describe population dynamics

We now want to have an analytical description of the collective
dynamics of this local network. We adopted the formalism presented in
[[citetext:ElBoustani2009]]. Two reasons motivated this choice: 1) because
10000 neurons is still far from the large network limit, finite-size
effects could have a significant impact on the dynamics and 2) because
of the relative complexity of the cellular models, an analytic
treatment of the type [[citetext:Amit1997]] is, to our knowledge, not
accessible and would be extremely challenging to derive. The Markovian
framework proposed in [[citetext:ElBoustani2009]] positively respond to
those two constraints: it is a second-order description of population
activity that describes fluctuations emerging from finite-size effects
and it is applicable to any neuron model as long as its transfer
function can be characterized. In a companion study [[cite:Zerlaut2016]],
we develloped a semi-analytical approach to characterize those
transfer functions (see next section), we will therefore incorporate
this description into the formalism.

Nonetheless, the study of [[citetext:ElBoustani2009]] only investigated
the ability of the formalism to describe 1) the stationary point of
the network activity and 2) in a situation where the neuronal models
models had an analytic estimate for the transfer function
(current-based integrate-and-fire model). Investigating whether this
description generalizes to transient dynamics and transfer functions
estimated with a semi-analytical approach is investigated in the next
sections.

** Transfer functions of excitatory and inhibitory cells

We briefly describe here the semi-analytical approach used to
characterize the transfer function (see details in the Methods).

The transfer function \(\mathcal{F}\) of a single neuron is defined
here as the function that maps the value of the stationary excitatory
and inhibitory presynaptic release frequencies to the output
stationary firing rate response, i.e. \(\nu_{out} = \mathcal{F}(\nu_e,
\nu_i)\). This kind of input-output functions lie at the core of
/mean-field/ models of population dynamics, reviewed in
[[citetext:Renart2004]] and is consequently the main ingredient of the
formalism adopted here [[cite:ElBoustani2009]]. Note here that the
formulation of the transfer function imply a stationary hypothesis:
both for the input (stationary Poisson processes) and the output
firing (a stationary firing rate). We will study in the following what
are the limitations introduced by this stationary hypothesis in the
description of the temporal dynamics of network activity.

In a previous communication [[cite:Zerlaut2016]], we found that the firing
rate response of several models (including the adaptative exponential
integrate and fire considered in this study) would be captured by a
/fluctuations-dependent/ threshold in a simple approximation of the
firing probability (see Methods).

The semi-analytical approach thus consisted in making numerical
simulations of single-cell dynamics for various presynaptic activity
levels (i.e. scanning various \(\nu_e, \nu_i\) configurations) and
measuring the output firing rate \(\nu_{out}\). All those
configurations corresponded to analytical estimates of
\((\mu_V,\sigma_V,\tau_V)\), we then fitted the
/fluctutations-dependent/ threshold that bring the analytical estimate
to the measured firing response. This procedure resulted in the
analytical estimates shown in Figure [[fig:tf]] and compared with the
results of numerical simulations.

** Spontaneous activity in the cortical column

#+ATTR_LATEX: :float multicolumn :width .7\linewidth
#+NAME: fig:phase-space
#+CAPTION: *Using the analytical description to look for a stable configuration of spontanous network activity.* Phase space of the dynamical system resulting from the first order of the markovian description, shown for two levels of external excitatory drive \(\nu_e^{drive}\). The lines represents trajectories resulting from different initial conditions. The vector field correspond to the time-evolution operator (the arrows represent the direction in the two-dimensional space and the color codes for the norm of the vector). *(A)* Phase space in the absence of an external drive \(\nu_e^{drive}\)=0Hz, the stable fixed point of the dynamics correspond to the quiescent network state \(\nu_e=\nu_i\)=0Hz. *(A)* Phase space with an external drive \(\nu_e^{drive}\)=4Hz, the stable fixed point of the dynamics correspond now corresponds to an active state with assymetric activity levels: \(\nu_e\)=1.6Hz and \(\nu_i\)=8.9Hz (round marker). 
[[../figures/finding_fixed_point.png]]

#+ATTR_LATEX: :width .7\linewidth
#+NAME: fig:ntwk-act
#+CAPTION: *Numerical simulations of the dynamics of a recurrent network of 10000 neurons (see parameters in Table [[table:params]])*. Note that all plots have the same x-axis: time. *(A)* Sample of the spiking activity of 500 neurons (green, 400 excitatory and red, 100 inhibitory). *(B)* Population activity (i.e. spiking activity sampled in 5ms time bins across the population) of the excitatory (green) and inhibitory (red) sub-populations. We also show the applied external drive (\(\nu_e^{drive}(t)\), black line), note the slow linear increase to reach \(\nu_e^{drive}\)=4Hz and try to reduce the initial synchronization that would result from an abrupt onset. *(C)* Membrane potential (top) and conductances (bottom, excitatory in green and inhibitory in red) time courses of three randomly choosen inhibitory neurons. *(D)* Membrane potential and conductances time courses of three randomly choosen excitatory neurons.
[[../figures/nwtk_activity.png]]


#+ATTR_LATEX: :width .8\linewidth
#+NAME: fig:mf-stat-pred
#+CAPTION: *Mean field prediction of the stationary activity.* Those quantities are evaluated after discarding the initial 500ms transient. *(A)* Gaussian predictions of the population activities (filled curve) compared to those observed in numerical simulations (empty bars). *(B)* Mean of the membrane potential and conductances time courses. Evaluated over 3 cells for the numerical simulations (empty bars, mean and standard deviation). *(C)* Standard deviation of membrane potential and conductances time courses.
[[../figures/mean_field_stat_pred.png]]

The combination of the transfer function and the markovian formalism
(Equation [[eq:master-equation]] in the Methods) yields our analytical
description of the layer II-III population dynamics in a single
cortical column.

We first use this analytical description to look for a physiological
configuration of spontaneous activity. There exists two qualitatively
different types of spontaneous asynchronous activity
[[cite:Vogels2005,Kumar2008]]: either the network is dominated by
inhibition and the network needs an asynchronous external excitatory
drive to exhibit spontaneous activity [[cite:Amit1997,Brunel2000]] or the
network exhibits an asynchronous self-sustained activity state and
just needs an initial "kick" to exit from the quiescent state
[[cite:Vogels2005,Kumar2008,ElBoustani2009]]. In the latter case, the
network is globally dominated by excitation and strong /shunting/
conductance effects prevents the network from an excitatory runaway
[[cite:Kuhn2004,Kumar2008]]. Those two behaviors are thus determined by
the membrane, synaptic and connectivity parameters. We therefore
investigate how the choosen network parameters in this study would
determine the qualitative nature of the spontaneous activity state.

In the case of a single electrophysiological type (e.g. excitatory and
inhibitory neurons taken as the same integrate-and-fire model), it was
shown that a simple /mean-field/ analysis allow to predict in which
situation the network parameters corresponds
[[cite:Brunel2000,Kumar2008]], here we generalized this approach to the
two populations considered in this study and we investigate the
behavior of our netowrk model given the parameters of Table
[[table:params]]. To this purpose, we simplified the dynamical system
describing population activity (Equation [[eq:master-equation]]) to its
first order so that we get a two dimensional system describing the
population spiking activity \(\nu_e(t)\) and \(\nu_i(t)\). We then
plotted the vector field of the time evolution operator in the phase
space of the dynamical system direction and launched some trajectories
with different initial conditions (see Figure [[fig:phase-space]]). The
result of this analysis is that, in absence of external input
(\(\nu_e^{drive}\)=0Hz), the only fixed point of the system is the
quiescent state (see Figure [[fig:phase-space]]A). This prediction of the
mean-field analysis was indeed confirmed by numerical simulations,
whatever the initial external "kick", the activity rapidly decayed
(T<50ms) to the quiescent state.

We conclude that, given the parameters of Table [[table:params]], our
network model does not have the ability to self-sustain activity and
will need an external excitatory drive to exhibit spontaneous activity
(note that this is also consistently with recent /in vivo/
observations in mice visual cortex, see
[[citetext:Reinhold2015]]). Indeed, when raising the external drive, a
non-quisecent fixed point appears (see Figure [[fig:phase-space]]B for
\(\nu_e^{drive}\)=4Hz). Numerical simulations confirmed the existence
of such a fixed point at those levels of activity (see Figure
[[fig:ntwk-act]]).

The particularity of this stationary fixed-point is its assymetry in
terms of population activity, it corresponds to \(\nu_e\)=1.6Hz and
\(\nu_i\)=8.9Hz (i.e. corresponding to a factor 5-6 between the their
respective firing rates). The origin of this assymetry is very
naturally the assymetry in electrophysiological properties as the
excitatory and inhibitory neurons sample statistically the same
recurrent and extrnal input. This phenomena has been observed in
extracellular recordings in human cortex [[cite:Peyrache2012]], cells
categorized as Fast-Spiking (such as our inhibitory cells) were shown
to fire 6-7 times more than cells categorized as Regular-Spiking (such
as our excitatory cells), an assymetry in excitabilities thus
naturally provides a putative explanation for this phenomena (rather
than specific circuitry).

** Accuracy of the description of the spontaneous activity state

We compare more closely the numerical simulation (Figure
[[fig:ntwk-act]]) to the prediction of the Markovian description.

First, we see that there is a transient period of \(\sim\) 400ms
resulting from the onset of the external drive (see Figure
[[fig:ntwk-act]]B-D), we will therefore evaluate stationary properties
after discarding the first 500ms of the simulation.

After this initial transient, the population activities (\(\nu_e\) and
\(\nu_i\)) fluctuates around the stationary levels (see Figure
[[fig:ntwk-act]]). The Markovian description predicts this phenomena as it
contains the impact of finite size effects (the network comprises
10000 neurons). In Figure [[fig:mf-stat-pred]]A, we can see that the
distributions of the excitatory and inhibitory population activities
are rather well predicted by the formalism (it slightly overestimates
the means of the population activities).

We also investigated whether the average neuronal and synaptic
quantities were well predicted by the Markovian formalism. Indeed, we
found a very good match for all quantities (see Figure
[[fig:mf-stat-pred]]B,C, mean and variance of membrane potential and
synaptic conductances). Only the standard deviation of the membrane
potential fluctuations was underestimated (Figure [[fig:mf-stat-pred]]C),
presumably because of residual synchrony in the dynamics whereas the
Markovian formalism assumes a purely asynchronous regime.

** Description of the response to time-varying input

#+ATTR_LATEX: :width .7\linewidth
#+NAME: fig:mf-temp-pred
#+CAPTION: *Network response to a time-varying input and associated prediction of the Markovian formalism.* For all plots, the x-axis corresponds to time. Shown after 500ms of initial stimulation. *(A)* Sample of the spiking activity of 500 neurons (green, 400 excitatory and red, 100 inhibitory). *(B)* Population activity (in 5ms bins) of the excitatory (green) and inhibitory (red) sub-populations. Superimposed is the mean and standard deviation over time predicted by the Markovian formalism. We also show the applied external stimulation (\(\nu_e^{aff}(t)\), dotted line). *(C)* Membrane potential time courses of three excitatory cells (green, top) and three inhibitory cells (red, bottom) with the prediction of the mean and standard deviation in time. *(D)* Conductance time courses of the six cells in *C* with the predictions of the fluctuations superimposed.
[[../figures/ntwk_time_varying.png]]

We now examine whether the formalism captures the response to
time-varying input. Here again, we set the input and examine the
response after 500ms of initial simulation to discard transient
effects.

We first choose an afferent input of relatively low frequency content
(\(\sim\) [5-20]Hz, \( \tau_1 \)=60ms and \( \tau_2 \)=100ms in
Equation [[eq:input]]). The afferent input waveform, formulated in terms
of firing rate, was translated into individual afferent spikes
targetting the excitatory population. The response of the network to
this input is shown in Figure [[fig:mf-temp-pred]] in comparison with the
prediction of the Markovian formalism. The excitatory population
activity raises and immediately entrains a raise of the inhibitory
population. The analytical description captures well the order of
magnitude of the deflection, it only slightly underestimates the peak
value (Figure [[fig:mf-temp-pred]]B). But the numerical simulations also
show a marked hyperpolarization after the stimulation, the return to
the baseline level happens only \(\sim\) 200-300 ms after the end of
the stimulus, and not immediately as predicted by the Markovian
framework. Here this strong hyperpolarization is the result of the
strong spike-frequency adaptation current that remains as a
consequence of the high activity evoked by the stimulus. In the
Markovian there is no memory of the previous activity and therefore
this phenomena can not be accounted for. This typically illustrates a
limitation of the analytical description provided here. Note that this
is not a fundamental limitation of the Markovian formalism, it is a
limitation of this version of the formalism, that contains only
variables related to the instantaneous activity (see Discussion).

#+ATTR_LATEX: :width .7\linewidth
#+NAME: fig:mf-freq-dep
#+CAPTION: *Limitations of the Markovian description in the frequency domain.* Response of the network (numerical simulation and analytical description) to sinusoidal stimulation of the form \(\nu_e^{aff} = 5\mathrm{Hz} \, \big(1-\cos(2 \pi f (t-t_0))\big)/2\). The stimulation was set on at \(t_0\)=500ms. The response was fitted by a function of the form  \(\nu(t) = A \, \big(1-\cos(2 \pi f (t-t_0) - \phi)\big)/2\). *(A)* Amplitude of the sinusoidal response (\(A\) in the fitted response) for various frequencies. *(B)* Phase shift of the sinusoidal response (\(\phi\) in the fitted response) for various frequencies.
[[../figures/freq_dep_of_network.png]]

To study more precisely the temporal validity of the formalism, we
modulated the network activity by sinusoidal input and compared the
response predicted by the analytical description.

The numerical simulations showed a marked resonance at
\(\sim\)50Hz. Given the relatively high strength (compared to the
external input) of the excitatory-inhibitory loop, the network is
close to a bifurcation toward oscillations that are typically in the
gamma range [[cite:Brunel2003]]. A sinusoidal input therefore amplifies
those frequencies [[cite:Ledoux2011]]. Because the individual excitatory
and inhibitory post-synaptic currents approximately match each other,
the theoretical study of [[citetext:Brunel2003]] would predict
oscillations at 50-60Hz (the bifurcation would be achieved by reducing
\(\tau_e\)), thus compatible with the present obsrevation.

More importantly, the main insight of this analysis is to show that
the network can track very fast temporal variations in the
input. Recurent neural networks globally behave as low-pass filters
(though see [[cite:Ledoux2011]] for a detailed treatment of the appearance
of resonances), but with a high cutoff frequency compared to the
frequency content of thalamic input of classical artificial stimuli
(drifting gratings, supra-10ms flashes, etc...).

Leaving apart the failure of capturing the network resonance (that is
linked to this special configuration of synaptic parameters), we
conclude that in the frequency range that will be used in the
following (f<50-100Hz) the description of the formalism gives a
relatively accurate description of the network response in the sense
that it accurately predicts that there should not be a frequency
filtering within this range. Again, /in vivo/ experiments in awake
mice suggested that V1 cortical networks had a cut-off frequency above
this range (\(sim\)100Hz in [[citetext:Reinhold2015]]).

** Integrative properties of the network

Now, we leave numerical simulations


#+ATTR_LATEX: :width .8\linewidth
#+NAME: fig:varying-amp-in-ntwk
#+CAPTION: *Varying input amplitudes in the mean field model.*
[[../figures/varying_input_amp.png]]


#+ATTR_LATEX: :width .8\linewidth
#+NAME: fig:varying-bg-in-ntwk
#+CAPTION: *Impact of background activity in the mean field model.*
[[../figures/impact_of_bg_act.png]]

** Embedding the model in a ring model to describe spatial integration

#+ATTR_LATEX: :float multicolumn :width .6\linewidth
#+NAME: fig:simple-stim
#+CAPTION: *A model of the cortical sheet.*
[[../figures/simple_stim.png]]

# #+ATTR_LATEX: :float multicolumn :width .8\linewidth
# #+NAME: fig:spt-temp-charact
# #+CAPTION: *Spatio-temporal characterization of the resulting pattern.*
# [[../figures/spatio_temporal_profile_charact.png]]

# ** Calibration on in vivo imaging :noexport:

# #+ATTR_LATEX: :float multicolumn :width .8\linewidth
# #+NAME: fig:data
# #+CAPTION: *Spatio-temporal characterization of the resulting pattern.*
# [[../figures/data.png]]

** Predictions of the model

#+ATTR_LATEX: :float multicolumn :width .6\linewidth
#+NAME: fig:suppression
#+CAPTION: *Apparent motion protocol and the associated spatio-temporal profile of suppression.*
[[../figures/suppression.png]]

* Discussion
\normalsize

We first investigated whether the Markovian formalism proposed in
[[citetext:ElBoustani2009]] is able to describe the temporal dynamics of
artificial neural networks. Though this formalism was shown to be an
relatively accurate description of the response simulated in numerical
networks, we highlighted two example phenomena that was missed by our
description. The relative complexity of the theoretical problem should
be stressed, indeed no exact treatment of this situation could be
achieved as this represents a really tough mathematical problem. 


By taking advantage of this theoretical work performed at the
mesoscopic level (\(\sim\) 10000 neurons) to analytically describe
population dynamics in terms of few variables, we were able to design
a tractable model of population dynamics in Layer II-III at the
\(\sim\) 30 millimeter scale of the neocortical sheet.

We studied the properties of this model in the context of multi-input
integration. In particular, we implemented a typical paradigm of
visual processing: the apparent motion protocol. Similarly to what is
observed /in vivo/ we found a strong suppression signal that
originating in the second stimulus that propagated toward the first
stimulus.

Unlike previous studies
[[cite:Brunel2000,Vogels2005,Kumar2008,ElBoustani2009]], we introduced
asymmetric electrophysiological properties between excitatory and
inhibitory cells. The reason was twofolds: first it was an insightful
step to demonstrate the relative accuracy of the markovian formalism
(with the semi-analytical approach) in a situation including this
increased complexity, but more importantly, this assymetry in the
excitabilities was the mechanism that led to a very strong suppression
in the response to multiple inputs. This feature produce an inhibitory
control of the mean membrane potential fluctuations. When the external
stimulation increases the local excitatory activity, inhibition is
recruited via recurrent connections and because of its higher
excitability this recruitment is stronger than for the excitatory
population (see e.g. Figure [[fig:mf-temp-pred]]B).

Other suppressive mechanisms were present in this model: conductance
shunting of the external input due to background activity
[[cite:Ho2000,Chance2002]] (where an increase in background activity is
evoked by the first stimulus) as well spike-frequency adaptation
currents (as least its stationary effect). The effect of those
mechanisms has been investigated in absence of the
electrophysiological assymetry (i.e. by considering pure FS cells
networks and pure RS cell network), they indeed produced a suppression
with a similar spatio-temporal pattern such as the one observed in the
experimental data. Nonetheless, when keeping their value to estimated
physiological range, the amplitude of the suppression was at least one
order of magnitude lower than that observed in experimental recordings
(not shown, but the slight suppression for the firing activity in
Figure [[fig:varying-bg-in-ntwk]]B is the trace of this effect), thus
suggesting that they weakly participate to this strong suppression
effect.

Note here that an important constraint to account for the observed
experimental data was that the strong suppressive mechanism would be
cortico-cortical. Depression at the thalamo-cortical synapses can
contribute to the suppression of cortical responses [[ref]], but this semt
unlikely to play here as the sensory stimuli are well separated in the
visual space and are likely to also be well separated in the thalamic
nucleus.

We envision several future directions for the present model.

First, the theoretical descriptions of the local cortical network
could be improved, 


For example the strong hyperpolarization of population activity after
a transient rise (see Figure [[fig:mf-temp-pred]]B) was shown to be missed
by the formalism under this version. Indeed, this version does not
have a memory of the previous activity levels and thus can not account
for the effect of the long-lasting spike-frequency adaptation
mechanism that has been strongly activated by the activity evoked by
the stimulus. This is easily solvable within the Markovian framework,
one can introduce a new variable: the "population adaptation current",
that can directly be derived from the equation of the AdExp model (not
shown).

 The simplicity and high tractability of this model in its current
form would allow several inclusion without running into the drawback
of a high computational cost.

Second, investigating other typical cortical phenomena. As an example,
the response to a stimulus depends on the level of ongoing activity
[[cite:Arieli1996]] dependency on the level of ongoing activity. When the
the ongoing activity is modulated by the level of afferent activity is
this model sufficient to describe the spatio-temporal variability in
evoked response ? etc...

* References 
\small

\bibliography{biblio}


