#+TITLE: A markovian model for spatio-temporal population dynamics in neocortex
#+AUTHOR:  Collab.: S. Chemla^1 & F. Chavane^1 (/in vivo/ VSD imaging)
#+DATE:  \textsc{Y. Zerlaut}^2 & \textsc{A. Destexhe}^2 
#+INCLUDE: my_template.org

* Key points summary :noexport:
\bfseries

- We investigate whether the markovian formalism proposed in
  [[citetext:ElBoustani2009]] allows to describe the population dynamics
  of a network of excitatory and inhibitory neurons with different
  electrophysiological properties.

- Comparison with numerical simulations.

- Investigating the integrative properties of the mean field model.

- Implementation in a ring geometry to describe the spatial
  integration across the neocortical sheet.

- Comparison with optical imaging of spatio-temporal dynamics in the
  primary visual cortex of awake behaving monkey (Chemla & Chavane,
  unpublished results).

\normalfont

* Abstract
\bfseries

The focus of the present communication is to design a theoretical
model of neocortical dynamics with the following properties: 1) it
operates at the temporal and spatial scales scanned by optical imaging
and 2) it has a correlate in terms of single-cell dynamics (in
particular membrane potential dynamics), so that the model can
directly generate predictions for the signal imaged by the
voltage-sensitive dye imaging technique.

In this communication, by comparing its prediction with numerical
simulations of artificial neural networks, we investigate whether the
markovian formalism proposed in [[citetext:ElBoustani2009]] allows to
describe the population dynamics of a network of excitatory and
inhibitory neurons with different electrophysiological properties. In
particular, we investigate whether this formalism generalizes to the
description of network dynamics in the presence of time-dependent
inputs. We find that, while missing a resonant behavior at
\(\sim\)70Hz, the response to slow modulations (0-40Hz) provides a
good approximation of the response of this complex numerical neural
networks. We next analyze the integrative properties of the model: how
does it responds to increasing stimuli strength or how is it modulated
by an increase in external background activity. We found that, while
the firing response scales linearly the response in terms of membrane
potential variations over the population exhibits a strong
suppression. We then embed this local network description
(\(\sim\)10000 neurons) in a ring geometry to describe the spatial
integration across the neocortical sheet. We re-construct a typical
experimental paradigm of visual processing: the apparent-motion
protocol and we compare the model's response to optical imaging of
spatio-temporal dynamics in the primary visual cortex of awake
behaving monkey (Chemla & Chavane, unpublished results). We found a
similar strong suppression as observed /in vivo/, our study therefore
proposes a precise mechanistic understanding of this phenomena.

\normalfont

* Introduction 
\normalfont

Recent advances in imaging technique, in particular voltage-sensitive
dye imaging (VSDi), have revealed fundamental properties of
neocortical processing
[[cite:Arieli1996,Contreras2001,Petersen2001,Ferezou2006,Civillico2012]]:
subthreshold responses to sensory inputs are locally homogeneous in
primary sensory areas, depolarizations tend to spread across spatially
neighboring regions and responses to sensory stimuli are strongly
affected by the level of ongoing activity. It also appears as great
tools to undesrtand how the spatio-temporal dynamics in the neocortex
shape canonical cortical operations such as normalization
[[cite:Reynaud2012]].


On the other hand, the litterature lacks, to our knowledge, a
theoretical model that provides a detailed account of those phenomena
with a clear relation between how this signal is generated and those
physiolgical principles at that spatial scale (i.e. at the millimeters
or centimeters scale).

The aim of the present communication is to design a theoretical model
of neocortical dynamics with the following properties: 1) it should
operate at the temporal and spatial scales of optical imaging and 2)
it has a correlate in terms of single-cell dynamics (in particular
membrane potential dynamics), so that the model can directly generate
predictions for the signal imaged by the VSDi technique
[[cite:Berger2007]].

More specifically, our study focuses on network dynamics in
/activated/ cortical states, thus the desired model should describe
neocortical computation in the asynchronous regime, where cortical
activity is characterized by irregular firing and strong subthreshold
fluctuations at the neuronal level [[cite:Steriade2001,Destexhe2003]]. The
strategy behind the present model is to take advantage of the
/mean-field/ descriptions of network dynamics in this regime. Via
self-consistent approaches, those descriptions allow to capture the
dynamical properties of population activity in recurrent networks
[[cite:Amit1997,Brunel1999,Brunel2000,Latham2000,ElBoustani2009]]. The
model thus relies on the following scheme: 1) we consider the randomly
connected network of 10000 neurons as a unit to describe a cortical
column and 2) we embeded the analytical description of this cortical
column model into a ring geometry with physiological local
connectivity profiles to model spatio-temporal integration on the
neocortical sheet.

A prerequisite was therefore to establish the accuracy of the
analytical description of the cortical column model. This is the focus
of the first part of this paper: by comparing analytical prediction of
the model with numerical simulations, we can precisely evaluate the
accuracy and/or weaknesses of the analytical description to evaluate
its potential impact on the modeling of the network.

The second part of the paper investigates the properties of the model

* Material and Methods
\small

We describe the equations and parameters used for the neuronal,
synaptic and network modeling. We present our /heuristic/ treatment of
the neuronal /transfer functions/: the quantity that accounts for the
cellular computation in /mean-field/ models of population
activity. Then, we present the specific markovian model of population
activity used in this study. Finally, we embed this description of
local population dynamics in a ring model to describe spatio-temporal
integration on the neocortical sheet.

** Single neuron models

The neuronal model used in this study is the adaptative exponential
and fire (AdExp) model [[cite:Brette2005a]]. The equation for the membrane
potential and the adaptation current therefore reads:

#+NAME: eq:iAdExp
\begin{equation}
\hspace{-.2cm}
  \left\{
  \begin{split}
  & C_\mathrm{m}\,\frac{dV}{dt} = g_\mathrm{L} \,(E_\mathrm{L}-V) + I_{syn}(V,t) + k_a e^{\frac{V - V_{thre} }{k_a}}- I_w \\
  & \tau_w \frac{d I_w}{dt} = - I_w + \sum_{t_s \in \{t_{spike}\}} b \, \, \delta (t-t_s)
  \end{split}
\right.
\end{equation}

where $I_{syn}(V, t)$ is the current emulating synaptic activity that
will create the fluctuations, $I_w$ reproduces the I_m current
[[cite:McCormick1985]]. The spiking mechanism is the following: when
$V(t)$ reaches \(V_{thre}+5 \, k_a \), this triggers a spike t_s \in
\{t_{spike}\}, this increases the adaptation variable $I_w$ by \(b\),
the membrane potential is then clamped at \(E_L\) for a duration
\tau_{refrac}=5ms. We consider two versions of this model: a regular
spkiking neuron for the excitatory cells and a fast spiking neuron for
the inhibitory cells (see Figure [[fig:tf]]). The parameters of those two
models can be found on Table [[table:params]].

#+ATTR_LATEX: :float multicolumn
#+NAME: table:params
#+CAPTION: *Model parameters*. The passive properties and the mean morphology are fitted while 
| *Parameters*          | Parameter Name                 | Symbol            | Value | Unit |
|-----------------------+--------------------------------+-------------------+-------+------|
| /                     | <>                             | <>                |    <> | /    |
|                       |                                |                   |       |      |
| *cellular properties* |                                |                   |       |      |
|                       | leak conductance               | \(g_L\)           |    10 | nS   |
|                       | leak reversal potential        | \(E_L\)           |   -65 | mV   |
|                       | membrane capacitance           | \(C_m\)           |   150 | pF   |
|                       | leak reversal potential        | \(E_L\)           |   -65 | mV   |
|                       | AP threshold                   | \(V_{thre}\)      |   -50 | mV   |
|                       | refractory period              | \(\tau_{refrec}\) |     5 | ms   |
|                       | adaptation time constant       | \(\tau_w\)        |   500 | ms   |
| *excitatory cell*     |                                |                   |       |      |
|                       | sodium sharpness               | \(k_a\)           |     2 | mV   |
|                       | adaptation current increment   | \(b\)             |    20 | pA   |
|                       | adaptation conductance         | \(a\)             |     4 | nS   |
| *inhibitory cell*     |                                |                   |       |      |
|                       | sodium sharpness               | \(k_a\)           |   0.5 | mV   |
|                       | adaptation current increment   | \(b\)             |     0 | pA   |
|                       | adaptation conductance         | \(a\)             |     0 | nS   |
| *numerical network*   |                                |                   |       |      |
|                       | cell number                    | \(N_{tot}\)       | 10000 |      |
|                       | connectivity probability       | \(\epsilon\)      |    5% |      |
|                       | fraction of inhibitory cells   | g                 |   20% |      |
|                       | external drive                 | \(\nu_e^{drive}\) |     4 | Hz   |
| *ring model*          |                                |                   |       |      |
|                       | total extent                   | \(L_{tot}\)       |    40 | mm   |
|                       | excitatory connectivity extent | \(l_{exc}\)       |     5 | mm   |
|                       | inhibitory connectivity extent | \(l_{inh}\)       |     1 | mm   |
|                       | propagation delay              | \(v_c\)           |   300 | mm/s |

** Synaptic model

The time- and voltage-dependent current that stimulate the neuron is
made of the sum of an excitatory and inhibitory currents (indexed by
\(s \in \{e,i\}\) and having a reversal potential \(E_s\)):

#+NAME: eq:syn-current
\begin{equation}
 I_{syn}(V,t) = \sum_{s \in \{e,i\}} \sum_{t_s \in \{t_s\}} Q_s \, e^{-\frac{t}{\tau_s}} \, (E_{s}-V) \, \mathcal{H}(t-t_s)
\end{equation}
where \(\mathcal{H}\) is the Heaviside function.

This synaptic model is refered to as the /conductance-based
exponential/ synapse. The set of events \(\{t_e\}\) and \(\{t_i\}\)
are the set of excitatory and inhibitory events arriving to the
neuron. In numerical simulations of single neurons, it will be
generated by stationary Poisson processes. In numerical simulations of
network dynamics it will correspond to the set of spike times of the
neurons connecting to the targent neurons, both via recurrent and
feedforward connectivity.

** Numerical network model

All simulations of numerical network were performed with the =brian2=
simulator [[cite:Goodman2009]], see [[http://brian2.readthedocs.org]]. For all
simulations, the network was composed of \(N_{tot}\)=10000 neurons,
separated in two populations, one excitatory and one inhibitory with a
ratio of g=20% inhibitory cells. Those two populations we recurrently
connected (internally and mutually) with a connectivity probability
\(\epsilon\)=5%.

Because this network did not display self-sustained activity (see
Figure [[fig:phase-space]], in contrast to [[citetext:Vogels2005]]), an
excitatory population exerted an /external drive/ to bring the network
out of the quiescent state. This population targetted both the
excitatory and inhibitory neurons. Note that the firing rate of this
population was linearly increased to avoid a too strong initial
synchronization (see Figure [[fig:ntwk-act]]). Finally, an excitatory
population of time varying firing rate could was added to evoke
activity transients in the population dynamics. This last stimulation
targetted only the excitatory population. The number of neurons in
those two excitatory populations was taken as identical to the number
of excitatory neurons (i.e. \((1-g)\,N_{tot}\)) and created synapses
onto the recurrent network with the same probability
\(\epsilon\). After temporal discretization, the firing rates of those
afferent populations were converted into spikes by using the
properties of a Poisson process (i.e. eliciting a spike at \(t\) with
a probability \(\nu(t) \,dt \)). All simulations were performed with a
time-step dt=0.1ms.

** Estimating the transfer functions of single neurons

The transfer function \(\mathcal{F}\) of a single neuron is defined
here as the function that maps the value of the stationary excitatory
and inhibitory presynaptic release frequencies to the output
stationary firing rate response, i.e. \(\nu_{out} = \mathcal{F}(\nu_e,
\nu_i)\). Note the stationary hypothesis in the definition of the
transfer function (see discussion in main text).

Because an analytical solution of this function for the single neuron
models considered in our study is a very challenging mathematical
problem, we adopted a semi-analytical approach. We performed numerical
simulations of single cell dynamics at various excitatory and
inhibitory presynaptic frequencies (\(\nu_e\) and \(\nu_i\)
respectively) (see the output in Figure [[fig:tf]]) on which we fitted the
coefficients of an analytical template to capture the single cell
model's response.

The procedure relied on fitting a /phenomenological threshold/
\(V_{thre}^{eff}\) that accounts for the single neuron non-linearities
(spiking and reset mechanism, adaptation mechanisms) on top of the
subthreshold integration effects [[cite:Zerlaut2016]]. This
phenomenological threshold is then plugged-in into the following
formula (analogous to [[citetext:Amit1997]]) to become our firing response
estimate:

#+NAME: eq:template
\begin{equation}
  \nu_{out} = \frac{1}{2\,\tau_V} \cdot 
  {Erfc}(\frac{V_{thre}^{eff}-\mu_V}{\sqrt{2} \, \sigma_V})
\end{equation}

Where \( (\mu_V, \sigma_V, \tau_V) \) are the mean, standard deviation
and autocorrelation time constant of the membrane potential
fluctuations. How to calculate those quantities as a response to a
stationary stimulation is the focus of the next section.

The phenomenological threshold was taken as a second order polynomial
in the three dimensional space \( (\mu_V, \sigma_V, \tau_V) \):

#+NAME: eq:quadratic-threshold
\begin{equation}
  \begin{split}
   V_{thre}^{eff} & (\mu_V, \sigma_V, \tau_V^N) = P_0 + 
   \sum_{x \in \{ \mu_V, \sigma_V, \tau_V^N\}} P_x \cdot \Big(  \frac{x - x^0}{\delta x^0} \Big) + \\
   & \sum_{ x,y \in \{ \mu_V, \sigma_V, \tau_V^N\}^2} P_{xy} \cdot
   \Big( \frac{x - x^0}{\delta x^0}  \Big) \,  \Big( \frac{y - y^0}{\delta y^0} \Big)
 \end{split}
\end{equation}

Where the normalization factors \(\mu_V^0\)=-60mV, \(\delta
\mu_V^0\)=10mV, \(\sigma_V^0\)=4mV, \(\delta \sigma_V^0\) = 6mV,
\(\tau_V^{N0}\)=0.5 and \(\delta \tau_V^{N0}\)= 1 arbitrarily delimits
the /fluctuation-driven/ regime (a mean value $x$ and an extent
$\delta x$, \(\forall x \in \{\mu_V, \sigma_V, \tau_V^N\}\)).  They
render the fitting of the phenomenological threshold easier, as they
insure that the coefficients take similar values. It is kept constant
all along the study. The phenomenological threshold was taken as a
second order polynomial and not as a linear threshold, for two
reasons: 1) unlike in an experimental study [[cite:Zerlaut2016]], we are
not limited by the number of sampling points, the number of fitted
coefficients can thus be higher as the probability of overfitting
becomes negligible 2) it gives more flexibility to the template,
indeed the linear threshold was found a good approximation in the
/fluctuation-driven/ regime, i.e. when the diffusion approximation
holds, however, for low values of the presynaptic frequencies, we can
be far from this approximation, the additional coefficients are used
to capture the firing response in those domains.


The fitting procedure was identical to [[citetext:Zerlaut2016]], it
consisted first in a linear regression in the phenomenological
threshold space of Equation [[eq:quadratic-threshold]], followed by a
non-linear optimization of Equation [[eq:template]] on the firing rate
response. Both fitting were performed with the =leastsq= method in the
=optimize= package of =SciPy=.

** Calculus of the subthreshold membrane potential fluctuations

Here, we detail the analytical calculus that translate the input to
the neuron into the properties of the membrane potential
fluctuations. The input is made of two Poisson shotnoise: one
excitatory and one inhibitory that are both convoluted with an
exponential waveform to produce the synaptic conductances time
courses.

*** Conductances fluctuations

From Campbell's theorem [[cite:Papoulis1991]], we first get the mean
(\(\mu_{Ge}, \mu_{Gi}\)) and standard deviation (\(\sigma_{Ge},
\sigma_{Gi}\)) of the excitatory and inhibitory conductance
fluctuations:

\begin{equation}
\begin{split}
& \mu_{Ge}(\nu_e, \nu_i) = \nu_e \, K_e \, \tau_e \, Q_e \\
& \sigma_{Ge}(\nu_e, \nu_i) = \sqrt{\frac{\nu_e \, K_e \, \tau_e}{2}} \, Q_e \\
& \mu_{Gi}(\nu_e, \nu_i) = \nu_i \, K_i \, \tau_i \, Q_i \\
& \sigma_{Gi}(\nu_e, \nu_i) = \sqrt{\frac{\nu_i \, K_i \, \tau_i}{2}} \, Q_i 
\end{split}
\end{equation}

The mean conductances will control the input conductance of the neuron
\(\mu_G\) and therefore its effective membrane time constant
\(\tau_m\):

\begin{equation}
\begin{split}
& \mu_{G}(\nu_e, \nu_i) = \mu_{Ge} + \mu_{Gi} + g_L \\
& \tau_m(\nu_e, \nu_i) = \frac{C_m}{\mu_{G}}\\
\end{split}
\end{equation}

*** Mean membrane potential

Following [[citetext:Kuhn2004]], the mean membrane potential is obtained
by taking the stationary solution to static conductances given by the
mean synaptic bombardement (for the passive version of Equation
[[eq:iAdExp]], i.e. removing the adaptation and spiking mechanisms). We
obtain:

#+NAME: eq:mu-v
\begin{equation}
\mu_V(\nu_e, \nu_i) = \frac{\mu_{Ge} \, E_e + \mu_{Gi} \, E_i + g_L \, E_L}{\mu_{G}}
\end{equation}

We will now approximate the driving force \(E_s - V(t)\) of synaptic
events by the level resulting from the mean conductance bombardment:
\(E_s - \mu_V\). This will enable an analytical solution for the
standard deviation \( \sigma_V\) and the autocorrelation time \(
\sigma_V\) of the fluctuations/

*** Power spectrum of the membrane potential fluctuations

Obtaining \( \sigma_V\) and \(\tau_V\) is achieved by computing the
power spectrum density of the fluctuations. In the case of Poisson
processes, the power spectrum density of the fluctuations resulting
from the sum of events \(PSP_{s}(t)\) at frequency \(K_{s} \, \nu_s\)
can be obtained from shotnoise theory [[cite:Daley2007]]:

\begin{equation}
\begin{split}
 P_V(f)  = & \sum_{s \in \{e,i\}} K_s \, \nu_{s} \, \| \hat{\mathrm{PSP}_s}(f) \|^2
\end{split}
\end{equation}

where \(\hat{\mathrm{PSP}_s}(f)\) is the Fourier transform of the
time-varying function \(\mathrm{PSP}(t)\). Note that the relations
presented in this paper rely on the following convention for the
Fourier transform: \( \hat{F}(f) = \int_\mathbb{R} F(t) \, e^{- 2 i
\pi f t} \, dt\).

After fixing the driving force to \(E_s - \mu_V\), the equation for a
 post-synaptic membrane potential event \(s\) around \(\mu_V\) is

\begin{equation}
 \tau_m \frac{d \, \mathrm{PSP}_s }{dt} + \mathrm{PSP}_s = U_s \, \mathcal{H}(t) \, e^{\frac{-t}{\tau_s}}
\end{split}
\right.
\end{equation}

where \( U_s = \frac{Q_s}{\mu_G} (E_s - \mu_V) \) and \(
\mathcal{H}(t) \) is the Heaviside function.

Its solution is:

\begin{equation}
\mathrm{PSP}_s(t)  = U_s \, \frac{\tau_s}{\tau_m - \tau_s} \, \big( 
e^{\frac{-t}{\tau_m}} - e^{\frac{-t}{\tau_s}} \big) \, \mathcal{H}(t)
\end{equation}

We take the fourier transform:

\begin{equation}
\hat{\mathrm{PSP}_s}(f) = U_s \, \frac{\tau_s}{\tau_m - \tau_s} \, 
\big(
\frac{\tau_{m}}{2 \, i  \,  \pi \, f \, \tau_{m} +1} 
- \frac{\tau_s}{2 \, i  \,  \pi \, f \, \tau_s +1} \big)
\end{equation}

We will need the value of the square modulus at \(f=0\):

#+NAME: eq:psp0
\begin{equation}
\| \hat{\mathrm{PSP}}(0) \|^2 = (U_s \cdot \tau_s)^2
\end{equation}

As well as the integral of the square modulus:

#+NAME: eq:psp-int
\begin{equation}
\int_\mathbb{R}  df \, \| \hat{\mathrm{PSP}}(f) \|^2 = \frac{(U_s \cdot \tau_s)^2}{2 \, (\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) }
\end{equation}

*** Standard deviation of the fluctuations

The standard deviation follows:

\begin{equation}
 (\sigma_V)^2  = \int_\mathbb{R}  df \, P_V(f)
\end{equation}

Using Equation [[eq:psp-int]], we find the final expression for \(\sigma_V\):

#+NAME: eq:sigma-v
\begin{equation}
 \sigma_V(\nu_e, \nu_i)  = \sqrt{ \sum_s K_s \, \nu_s \, \frac{(U_s \cdot \tau_s)^2}{2 \, (\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) } }
\end{equation}

*** Autocorrelation-time of the fluctuations

We defined the global autocorrelation time as [[cite:Zerlaut2016]]:

\begin{equation}
  \tau_V = \frac{1}{2} \, \big( \frac{\int_\mathbb{R} P_V(f) \, d f}{ P_V(0) } \big)^{-1}
\end{equation}

Using Equations [[eq:psp-int]] and [[eq:psp0]], we find the final expression
for \(\tau_V\):

#+NAME: eq:tau-v
\begin{equation}
  \tau_V(\nu_e, \nu_i) = \Big( \frac{
  \sum_s \big( K_s \, \nu_s \, (U_s \cdot \tau_s)^2\big) 
  }{
  \sum_s \big( K_s \, \nu_s \, (U_s \cdot \tau_s)^2 /(\tau_\mathrm{m}^\mathrm{eff} + \tau_s ) \big)
  } \Big)
\end{equation}

Therefore the set of Equations [[eq:mu-v]], [[eq:sigma-v]] and [[eq:tau-v]]
translate the presynaptic frequencies into membrane fluctuations
properties \(\mu_V, \sigma_V, \tau_V\).

The previous methodological section allowed to translate the
fluctuations properties \(\mu_V, \sigma_V, \tau_V\) into a spiking
probability thanks to a minimization procedure. The combination of the
present analytical calculus and the previous fitting procedure (on
numerical simulations data) constitute our semi-analytical approach to
determine the transfer function of a single cell model: \( \nu_{out} =
\mathcal{F}(\nu_e, \nu_i)\).

** Master equation for local population dynamics

An analytical description of the cellular transfer function is the
core of theoretical descriptions of asynchronous dynamics in sparsely
connected random networks [[cite:Amit1997,Brunel2000,Renart2004]].

Because we will investigate relatively slow dynamics
(\(\tau\)>25-50ms) (and because of the stationary formulation of our
transfer function), we will use the Markovian description develloped
in [[citetext:ElBoustani2009]], it describes network activity at a time
scale \(T\), for which the network dynamics should be Markovian. The
choice of the time-scale \(T\) is quite crucial in this formalism, it
should be large enough so that activity can be considered as
memoryless (e.g. it can not be much smaller than the refractory
period, that would introduce memory effects) and small enough so that
each neuron can fire statistically only once per time interval
\(T\). Following [[citetext:ElBoustani2009]], we will arbitrarily take
\(T\)=5ms all along the study as it offers a good compromise between
those two constraints. 


The formalism describes the first and second moments of the population
activity for each populations. We consider here two populations: one
excitatory and one inhibitory, the formalism thus describes the
evolution of five quantities: the two means \(\nu_e(t)\) and
\(\nu_i(t)\) of the excitatory and inhibitory population activity
respectively (the instantaneous population firing rate, i.e. after
binning in bins of \(T\)=5ms, see discussion in
[[citetext:ElBoustani2009]]), the two variances \(c_{ee}(t)\) and
\(c_{ii}(t)\) of the the excitatory and inhibitory population activity
respectively and the covariance \(c_{ei}(t)\) between the excitatory
and inhibitory population activities. The set of differential
equations followed by those quantities reads [[cite:ElBoustani2009]]:

#+NAME: master-equation
\begin{equation}
\left\{
\begin{split}
T \, \frac{\partial \nu_\mu}{\partial t} = & (\mathcal{F}_\mu - \nu_\mu )
   + \frac{1}{2} \, c_{\lambda \eta} \, 
\frac{\partial^2 \mathcal{F}_\mu}{\partial \nu_\lambda \partial \nu_\eta} \\
T \, \frac{\partial c_{\lambda \eta} }{\partial t}  =  & A_{\lambda \eta} +
(\mathcal{F}_\lambda - \nu_\lambda ) \, (\mathcal{F}_\eta - \nu_\eta ) + \\
 & c_{\lambda \mu} \frac{\partial \mathcal{F}_\mu}{\partial \nu_\lambda} +
 c_{\mu \eta} \frac{\partial \mathcal{F}_\mu}{\partial \nu_\eta} 
 - 2  c_{\lambda \eta}
\end{split}
\right.
\end{equation}

with:
\begin{equation}
A_{\lambda \eta} =  
\left\{
\begin{split}
\frac{\mathcal{F}_\lambda \, (1/T - \mathcal{F}_\lambda)}{N_\lambda} 
\qquad & \textrm{if  } \lambda=\eta \\
0 \qquad & \textrm{otherwise}
\end{split}
\right.
\end{equation}

Note that, for the concision of the expressions, we used Einstein's
index summation convention: if an index is repeated in a product, a
summation over the whole range of value is implied (e.g. we sum over
\(\lambda \in \{e,i\} \) in the first equation, note that,
consequently, \(\lambda\) does not appear in the left side of the
equation). Also the dependency of the firing rate response to the
excitatory and inhibitory activities has been omitted: yielding
\(\mathcal{F}_\mu\) instead of \(\mathcal{F}_\mu(\nu_e,\nu_i)\),
\(\forall \mu \in \{e,i\} \).

** Ring model 

We now embed the previous markovian description of population dynamics
in a ring geometry to model spatio-temporal integration on the
neocortical sheet. For simplicity, we consider here only the first
moments of the second-order description: i.e. the means of the
excitatory and inhibitory population activities: \(\nu_e(t)\) and
\(\nu_i(t)\) respectively. 

We introduce the gaussian connectivity profiles (see Figure
[[fig:simple-stim]]) that defines the connectivity across cortical columns
(i.e. local networks described in the previous section):

\begin{equation}
\mathcal{N}_e(x) = \frac{1}{\sqrt{2 \pi} l_e} e^{-(\frac{x}{\sqrt{2} l_e})^2} \quad ; \quad 
\mathcal{N}_i(x) = \frac{1}{\sqrt{2 \pi} l_i} e^{-(\frac{x}{\sqrt{2} l_i})^2}
\end{equation}

where \(l_e\) and \(l_i\) are the excitatory and inhibitory extent of
the connectivity profiles respectively.

We also introduce the effect of a finite axonal conduction speed
\(v_c\), this will intriduce delays for the propagation of activity
across cortical columns: for a network at a distance \(x\), the
afferent activity will arrive delayed by \(x/v_c\).

Finally, the equations that govern the activity in space and time are
given by:

\begin{equation}
\left\{
\begin{split}
\nu_e^{input}(x,t) = &\nu_e^{drive}  + 
\int_\mathbb{R} dy \, \mathcal{N}_e(x-y) \, \nu_e(y, t-\|y-x\|/v_c) \\
\nu_i^{input}(x,t) = & \int_\mathbb{R} dy \, \mathcal{N}_i(x-y) \, \nu_i(y, t-\|y-x\|/v_c) \\
T \frac{\partial \nu_e(x,t)}{\partial t} = & -  \nu_e(x,t) + \\
& \mathcal{F}_e(\nu_e^{aff}(x,t)+\nu_e^{input}(x,t), \nu_i^{input}(x,t) ) \\
T \frac{\partial \nu_i(x,t)}{\partial t} = & -  \nu_i(x,t) + \mathcal{F}_i(\nu_e^{input}(x,t), \nu_i^{input}(x,t) )
\end{split}
\right.
\end{equation}

where \(\nu_e^{drive}\) is the external drive and \(\nu_e^{aff}(x,t)\)
is the afferent (thalamic) stimulation.

The local correlate in terms of mean membrane potential \(\mu_V(x,t)\)
is given by Equation [[eq:mu-v]].

** Evidencing propagation effects

Similar to [[cite:Muller2014]]

* Results
\normalsize

#+ATTR_LATEX: :float multicolumn :width .7\linewidth
#+NAME: fig:tf
#+CAPTION: *Single cell models of the excitatory and inhibitory populations.* Top: response to a current step of 200pA lasting 300ms. Bottom: /transfer function/ of the single cell, i.e. output firing rate as a function of the excitatory (x-axis) and inhibitory (color-coded) presynaptic release frequencies. Note that the range of the excitatory and frequencies assumes numbers of synapses (\(K_e\)=40 and \(K_i\)=10 for the excitation and inhibition respectively).  *(A)* Excitatory cells. Note the presence of spike-frequency adaptation and subthreshold adaptation. *(B)* Inhibitory cells. Note the very narrow spike initiation dynamics (\(k_a\)=0.5mV). Also, note the steepest relation to excitation (with respect to the excitatory cell) at various inhibitory levels as a result of the increased exctability as a result of the increased excitaability of the inhibitory cell (with respect to the excitatory cell).
[[../figures/tf.png]]

The results are organized as follows. We first construct the
analytical model that will describe the dynamics of a single cortical
column. In particular, we describe the semi-analytical workflow that
enables the derivation of the cellular transfer function: the core of
the population model. Next, we investigate whether the analytical
description accurately descrive population dynamics by comparing its
prediction to numerical simulations. Thenm we investigate the
integrative properties of the network model. Finally we embed the
cortical column model into a ring model and we compare its predictions
to VSDi recordings in the visual cortex of awake behaving monkey.

** Modeling a single cortical column

Because optical imaging presumably sample most of its signals from
superficial layers, we model here the layer II/III network: it is
characterized by a strong recurrent connectivity and an important
cellular diversity, in particular one finds many types of interneurons
[[cite:Markram2004,Ascoli2008a]]. We adopt here a very simplistic
description of this network, it is made of two neuronal population:
one excitatory and one inhibitory comprising 8000 and 2000 neurons
respectively. All neurons within the two population synaptically
interconnect randomly to each other with a connectivity probability of
5%. The excitatory and inhibitory cells have the same passive
properties. We nonetheless include an assymetry between the excitatory
and inhibitory populations: because the inhibitory population includes
Fast-Spiking cells that can exhibit very high firing frequencies
[[cite:Markram2004]], we set its spiking mechanism sharper (more precisely
its sodium activation activation curve is steeper, see Methods) than
that of excitatory cells, additionally we add a strong spike-frequency
adaptation current in excitatory cells that is absent in inhibitory
cells. Those two effects render the inhibitory neurons more excitable
(see the different responses to the same current step in Figure
[[fig:tf]]). All parameters of the cortical column can be found in Table
[[table:params]].

** A Markovian model to describe population dynamics

We now want to have an analytical description of the collective
dynamics of this local network. We adopted the formalism presented in
[[citetext:ElBoustani2009]]. Two reasons motivated this choice: 1) because
10000 neurons is still far from the large network limit, finite-size
effects could have a significant impact on the dynamics and 2) because
of the relative complexity of the cellular models, an analytic
treatment of the type [[citetext:Amit1997]] is, to our knowledge, not
accessible and would be extremely challenging to derive. The Markovian
framework proposed in [[citetext:ElBoustani2009]] positively respond to
those two constraints: it is a second-order description of population
activity that describes fluctuations emerging from finite-size effects
and it is applicable to any neuron model as long as its transfer
function can be characterized. In a companion study [[cite:Zerlaut2016]],
we develloped a semi-analytical approach to characterize those
transfer functions (see next section), we will therefore incorporate
this description into the formalism.

Nonetheless, the study of [[citetext:ElBoustani2009]] only investigated
the ability of the formalism to describe 1) the stationary point of
the network activity and 2) in a situation where the neuronal models
models had an analytic estimate for the transfer function
(current-based integrate-and-fire model). Investigating whether this
description generalizes to transient dynamics and transfer functions
estimated with a semi-analytical approach is investigated in the next
sections.

#+ATTR_LATEX: :float multicolumn :width .7\linewidth
#+NAME: fig:phase-space
#+CAPTION: *Finding spontaneous activity configuration (fixed point of the dynamics) of dynamics with external drive.*
[[../figures/finding_fixed_point.png]]

** Transfer functions of excitatory and inhibitory cells

We briefly describe here the semi-analytical approach used to
characterize the transfer function (see details in the Methods).

The transfer function \(\mathcal{F}\) of a single neuron is defined
here as the function that maps the value of the stationary excitatory
and inhibitory presynaptic release frequencies to the output
stationary firing rate response, i.e. \(\nu_{out} = \mathcal{F}(\nu_e,
\nu_i)\). This kind of input-output functions lie at the core of
/mean-field/ models of population dynamics, reviewed in
[[citetext:Renart2004]] and is also the main ingredient of the formalism
adopted here [[cite:ElBoustani2009]]. Note here that the formulation of
the transfer function imply a stationary hypothesis: both for the
input (stationary Poisson processes) and the output firing (a
stationary firing rate). We will study in the following what are the
limitations introduced by this stationary hypothesis in the
description of the temporal dynamics of network activity.

In a previous communication [[cite:Zerlaut2016]], we found that the firing
rate response of several models (including the adaptative exponential
integrate and fire considered in this study) would be captured by a
/fluctuations-dependent/ threshold in a simple approximation of the
firing probability (see Methods).

The semi-analytical approach thus consisted in making numerical
simulations of single-cell dynamics for various presynaptic activity
levels (i.e. scanning various \(\nu_e, \nu_i\) configurations) and
measuring the output firing rate \(\nu_{out}\). All those
configurations corresponded to analytical estimates of
\((\mu_V,\sigma_V,\tau_V)\), we then fitted the
/fluctutations-dependent/ threshold that bring the analytical estimate
to the measured firing response. This procedure resulted in the
analytical estimates shown in Figure [[fig:tf]] and compared with the
results of numerical simulations.

#+ATTR_LATEX: :width .7\linewidth
#+NAME: fig:ntwk-act
#+CAPTION: *Network activity of the configuration corresponding to the fixed point.*
[[../figures/nwtk_activity.png]]

** Looking for configurations of spontaneous activity in the cortical column

We now have a 

 investigate the predictive power of this semi-analytical
procedure. The first problem is to look at the network configuration
predicted by this workflow.

** Accuracy of the description of the spontaneous activity state

#+ATTR_LATEX: :width .8\linewidth
#+NAME: fig:mf-stat-pred
#+CAPTION: *Mean field prediction of the stationary activity.*
[[../figures/mean_field_stat_pred.png]]

** Applicability to time-varying input
#+ATTR_LATEX: :float multicolumn :width .45\linewidth
#+NAME: fig:mf-temp-pred
#+CAPTION: *Network response to a time-varying input and the associated prediction of the mean-field formalism.*
[[../figures/ntwk_time_varying.png]]

** Limitations of the markoviann description

Close to a Hopf bifurcation, see Kumar et al.

#+ATTR_LATEX: :float multicolumn :width .3\linewidth
#+NAME: fig:mf-freq-dep
#+CAPTION: *Accuracy of the mean field prediction in the frequency domain.*
[[../figures/freq_dep_of_network.png]]

** Integrative properties of the network
#+ATTR_LATEX: :float multicolumn :width .8\linewidth
#+NAME: fig:varying-amp-in-ntwk
#+CAPTION: *Varying input amplitudes in the mean field model.*
[[../figures/varying_input_amp.png]]

#+ATTR_LATEX: :float multicolumn :width .8\linewidth
#+NAME: fig:varying-ng-in-ntwk
#+CAPTION: *Impact of background activity in the mean field model.*
[[../figures/impact_of_bg_act.png]]

** Embedding the model in a ring model to describe spatial integration

#+ATTR_LATEX: :float multicolumn :width .99\linewidth
#+NAME: fig:simple-stim
#+CAPTION: *A model of the cortical sheet.*
[[../figures/simple_stim.png]]

#+ATTR_LATEX: :float multicolumn :width .8\linewidth
#+NAME: fig:spt-temp-charact
#+CAPTION: *Spatio-temporal characterization of the resulting pattern.*
[[../figures/spatio_temporal_profile_charact.png]]

** Calibration on in vivo imaging

#+ATTR_LATEX: :float multicolumn :width .8\linewidth
#+NAME: fig:data
#+CAPTION: *Spatio-temporal characterization of the resulting pattern.*
[[../figures/data.png]]

** Predictions of the model

#+ATTR_LATEX: :float multicolumn :width .8\linewidth
#+NAME: fig:suppression
#+CAPTION: *Apparent motion protocol and the associated spatio-temporal profile of suppression.*
[[../figures/suppression.png]]

* Discussion
\normalsize

By taking advantage of the theoretical work performed at the
mesoscopic level (\(\sim\) 10000 neurons) to analytically describe
population dynamics in terms of few variables, we were able to design
a tractable model of population dynamics in Layer II-III at the
\(\sim\) 30 millimeter scale of the neocortical sheet.

We investigated whether the Markovian formalism proposed in
[[citetext:ElBoustani2009]] is able to describe the temporal dynamics of
artificial neural networks. Answering this kind of question precisely
set what is the relevance of /stationary/ responses and what are real
transient effects. The hyperpolarization (unpublished observations)

We studied the properties of this model in the context of multi-input
integration. In particular, we implemented a typical paradigm of
visual processing: the apparent motion protocol. Similarly to what is
observed /in vivo/ we found a strong suppression signal that
originating in the second stimulus that propagated toward the first
stimulus.

Why not considering symmetric electrophysiological properties like in
other network studies [[cite:Brunel2000,Vogels2005,Kumar2008]]. The reason
was twofolds: first it was an insightful step to demonstrate the
relative accuracy of the markovian formalism (with the semi-analytical
approach) in a situation including this increased complexity, but more
importantly, this assymetry in the excitabilities was the mechanism
that led to a very strong suppression in the response to multiple
inputs. This feature produce an inhibitory control of the mean
membrane potential fluctuations. When the external stimulation
increases the local excitatory activity, inhibition is recruited via
recurrent connections and because of its higher excitability this
recruitment is stronger than for the excitatory population (see
e.g. Figure [[fig:mf-temp-pred]]B).

Other possible mechanisms for suppression were considered, in
particular conductance shunting of the input due to background
activity, spike-frequency adaptation currents. Note here that an
important constraint to account for the observed experimental data was
that the strong suppressive mechanism would be
cortico-cortical. Depression at the thalamo-cortical synapses can
contribute to the suppression of cortical responses [[ref]], but this semt
unlikely to play here as the sensory stimuli are well separated in the
visual space and are likely to also be well separated in the thalamic
nucleus.

We envision several future directions for the present model.

First, to improve the theoretical descriptions of the local cortical
network, for example the hyperpolarization can be described by adding
a variable: the "population spike-frequency adaptation current" (not
shown).

Second, implementing the model to several cortical includes: stimulus
response dependency to the level of ongoing activity [[cite:Arieli1996]]
dependency on the level of ongoing activity. When the the ongoing
activity is modulated by the level of afferent activity is this model
sufficient to describe the spatio-temporal

* References 
\small

\bibliography{biblio}


